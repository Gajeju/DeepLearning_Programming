{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3080684909962237\n",
      "=== epoch:1, train acc:0.127, test acc:0.118 ===\n",
      "train loss:2.283425530667471\n",
      "train loss:2.2663063608115124\n",
      "train loss:2.302790118700221\n",
      "train loss:2.2792834020575246\n",
      "train loss:2.3010502375600783\n",
      "train loss:2.2539870188659017\n",
      "train loss:2.2792331762481184\n",
      "train loss:2.2764731489848034\n",
      "train loss:2.269681373157697\n",
      "train loss:2.2818738094729913\n",
      "train loss:2.2729258571357507\n",
      "train loss:2.2722703554868726\n",
      "train loss:2.2359358957900053\n",
      "train loss:2.2406638672961487\n",
      "train loss:2.239271946767461\n",
      "train loss:2.2281199762293733\n",
      "train loss:2.24377085662736\n",
      "train loss:2.2221361267589383\n",
      "train loss:2.1678783619709283\n",
      "train loss:2.244585274871738\n",
      "train loss:2.174006997794102\n",
      "train loss:2.203178522233892\n",
      "train loss:2.1504381978846414\n",
      "train loss:2.048194693504041\n",
      "train loss:2.1708505413500494\n",
      "train loss:2.131896983331953\n",
      "train loss:2.031461920867065\n",
      "train loss:2.093124887656331\n",
      "train loss:1.9442194554794117\n",
      "train loss:2.053068783317929\n",
      "train loss:2.054530657951068\n",
      "train loss:1.9712768107268193\n",
      "train loss:1.9597923761131697\n",
      "train loss:2.0714380875106584\n",
      "train loss:2.0395181157968985\n",
      "train loss:1.9275537486801944\n",
      "train loss:1.992744801894014\n",
      "train loss:1.918862232423787\n",
      "train loss:1.7893731737925205\n",
      "train loss:1.8318523578281942\n",
      "train loss:1.8131756479937076\n",
      "train loss:1.755334778439131\n",
      "train loss:1.861215679898165\n",
      "train loss:1.8637934177205535\n",
      "train loss:1.8624802749670204\n",
      "train loss:1.8345128487948525\n",
      "train loss:1.7596846958366514\n",
      "train loss:1.861103357454274\n",
      "train loss:1.7894491507119705\n",
      "train loss:1.7122178354564956\n",
      "train loss:1.8375403413003533\n",
      "train loss:1.5342491875443756\n",
      "train loss:1.67431231813834\n",
      "train loss:1.5716722528170428\n",
      "train loss:1.6477972742289761\n",
      "train loss:1.5427960381010906\n",
      "train loss:1.7872069063643397\n",
      "train loss:1.6660176296313205\n",
      "train loss:1.6842145691027641\n",
      "train loss:1.5412385076137745\n",
      "train loss:1.7142841367045756\n",
      "train loss:1.6453756308739418\n",
      "train loss:1.609177186818279\n",
      "train loss:1.751698795837059\n",
      "train loss:1.62775856094693\n",
      "train loss:1.6426011586527762\n",
      "train loss:1.4760557484730454\n",
      "train loss:1.65511083541824\n",
      "train loss:1.4244563240289716\n",
      "train loss:1.6507860230005464\n",
      "train loss:1.4728321510055318\n",
      "train loss:1.660234702195187\n",
      "train loss:1.5230880332924353\n",
      "train loss:1.481101883838669\n",
      "train loss:1.5163164552065422\n",
      "train loss:1.6142795758650257\n",
      "train loss:1.661620940423257\n",
      "train loss:1.6646352221383194\n",
      "train loss:1.5950427860031535\n",
      "train loss:1.6302352509990192\n",
      "train loss:1.5547960119145587\n",
      "train loss:1.4001471314618479\n",
      "train loss:1.4186650459123877\n",
      "train loss:1.3457537364540955\n",
      "train loss:1.4313895669130492\n",
      "train loss:1.5896500100086937\n",
      "train loss:1.5109958467637454\n",
      "train loss:1.41004182304\n",
      "train loss:1.288035487117463\n",
      "train loss:1.466771756400738\n",
      "train loss:1.5733691557672125\n",
      "train loss:1.4177722100409207\n",
      "train loss:1.5733993587637556\n",
      "train loss:1.3433757763244365\n",
      "train loss:1.519355956696898\n",
      "train loss:1.2370369398149625\n",
      "train loss:1.4661654897737817\n",
      "train loss:1.4298713575283262\n",
      "train loss:1.6637650504968269\n",
      "train loss:1.566445126642545\n",
      "train loss:1.4940286760135755\n",
      "train loss:1.4357832043802374\n",
      "train loss:1.4871792463437086\n",
      "train loss:1.380758389914665\n",
      "train loss:1.52347703632704\n",
      "train loss:1.4305937440169711\n",
      "train loss:1.5409455796071683\n",
      "train loss:1.4770198100986758\n",
      "train loss:1.2890792797047854\n",
      "train loss:1.3369251834992784\n",
      "train loss:1.200226499319261\n",
      "train loss:1.4091715512295835\n",
      "train loss:1.2904775962465633\n",
      "train loss:1.3419111364522884\n",
      "train loss:1.3424267913632368\n",
      "train loss:1.5024142123660877\n",
      "train loss:1.4543550076346508\n",
      "train loss:1.6433622712714462\n",
      "train loss:1.4157503952040338\n",
      "train loss:1.4154150050607286\n",
      "train loss:1.3464475359439163\n",
      "train loss:1.4430405952671472\n",
      "train loss:1.326443513429206\n",
      "train loss:1.3505395626806558\n",
      "train loss:1.336769265175364\n",
      "train loss:1.2785195006341086\n",
      "train loss:1.3930455106273203\n",
      "train loss:1.3578925655198766\n",
      "train loss:1.4325070934480022\n",
      "train loss:1.2843964000406722\n",
      "train loss:1.4859471046860702\n",
      "train loss:1.566812664394321\n",
      "train loss:1.3140290223112567\n",
      "train loss:1.4388682205006702\n",
      "train loss:1.4000119799581756\n",
      "train loss:1.3284827916131914\n",
      "train loss:1.2067616304345439\n",
      "train loss:1.1832375557824177\n",
      "train loss:1.2521192758238475\n",
      "train loss:1.2462609012116919\n",
      "train loss:1.5760726266198801\n",
      "train loss:1.454449982303005\n",
      "train loss:1.2886496024532468\n",
      "train loss:1.3053957680536425\n",
      "train loss:1.2515278731155035\n",
      "train loss:1.4385244193007298\n",
      "train loss:1.377655969547259\n",
      "train loss:1.347678243797764\n",
      "train loss:1.2591785595129072\n",
      "train loss:1.487479238824271\n",
      "train loss:1.178924005669453\n",
      "train loss:1.4142080013945597\n",
      "train loss:1.2337438220149612\n",
      "train loss:1.301285158748366\n",
      "train loss:1.1760300864322133\n",
      "train loss:1.191864000589959\n",
      "train loss:1.1812094466185183\n",
      "train loss:1.2790913886980717\n",
      "train loss:1.2649508919998762\n",
      "train loss:1.2638584658072514\n",
      "train loss:1.2048166541132403\n",
      "train loss:1.3723018272304628\n",
      "train loss:1.321071939889043\n",
      "train loss:1.1948091816061157\n",
      "train loss:1.2795849696142618\n",
      "train loss:1.2662198497871429\n",
      "train loss:1.120655857395141\n",
      "train loss:1.169072819363552\n",
      "train loss:1.228688282472109\n",
      "train loss:0.9915664406929326\n",
      "train loss:1.304345002575512\n",
      "train loss:1.2592617840102844\n",
      "train loss:1.3101060058616343\n",
      "train loss:1.1518163799544852\n",
      "train loss:1.1943637556909252\n",
      "train loss:1.2458360918278744\n",
      "train loss:1.1705962105204621\n",
      "train loss:1.1416395409068085\n",
      "train loss:1.2142821606285994\n",
      "train loss:1.3507741316137507\n",
      "train loss:1.1489587604532228\n",
      "train loss:1.2178680808180473\n",
      "train loss:1.361881185658182\n",
      "train loss:1.2915626854859619\n",
      "train loss:1.3772450609708704\n",
      "train loss:1.2508343316167574\n",
      "train loss:1.0872709966598122\n",
      "train loss:1.086239326419318\n",
      "train loss:1.2868353631527\n",
      "train loss:1.1357292680869113\n",
      "train loss:1.2113007821266124\n",
      "train loss:1.2042693381875607\n",
      "train loss:1.306954908314569\n",
      "train loss:1.1611615679874443\n",
      "train loss:1.0272591663445503\n",
      "train loss:1.2837614987927746\n",
      "train loss:1.0253366927786074\n",
      "train loss:0.9064635572429341\n",
      "train loss:1.2177931962689783\n",
      "train loss:1.1042315667805036\n",
      "train loss:1.1403728375716613\n",
      "train loss:1.4805071996882557\n",
      "train loss:1.234857349236368\n",
      "train loss:1.2141955939754754\n",
      "train loss:1.25023675389581\n",
      "train loss:1.3199573426476072\n",
      "train loss:1.13343221966758\n",
      "train loss:1.0723954118200545\n",
      "train loss:1.1143724684516862\n",
      "train loss:1.04503428548288\n",
      "train loss:1.1075156956669512\n",
      "train loss:1.0582371596544398\n",
      "train loss:1.2717549366310186\n",
      "train loss:1.121373054188098\n",
      "train loss:1.2726285729835278\n",
      "train loss:1.286230611682632\n",
      "train loss:1.177698513065511\n",
      "train loss:1.1621092233460246\n",
      "train loss:1.0116804381254396\n",
      "train loss:1.2496214377497366\n",
      "train loss:0.95341894377658\n",
      "train loss:1.4147057804012724\n",
      "train loss:1.375537763438115\n",
      "train loss:1.21332067852539\n",
      "train loss:1.3291495524762396\n",
      "train loss:1.1799337783563049\n",
      "train loss:1.2843638115209302\n",
      "train loss:1.381068193126294\n",
      "train loss:1.1612630259937635\n",
      "train loss:1.259625424744347\n",
      "train loss:1.073009100131525\n",
      "train loss:1.235799116014073\n",
      "train loss:1.3266257451754262\n",
      "train loss:1.2765326293084658\n",
      "train loss:1.2606289759301352\n",
      "train loss:1.1393626033386548\n",
      "train loss:1.24520895801417\n",
      "train loss:1.1436129894204334\n",
      "train loss:1.1948852721519077\n",
      "train loss:1.1715877169464317\n",
      "train loss:1.446753011580658\n",
      "train loss:1.1356568153671476\n",
      "train loss:1.0804639195563441\n",
      "train loss:1.1202118028412236\n",
      "train loss:1.2534602069573018\n",
      "train loss:1.0979328226756884\n",
      "train loss:1.1043017024954331\n",
      "train loss:1.26647346756945\n",
      "train loss:1.3514323784183062\n",
      "train loss:1.2181978916185292\n",
      "train loss:1.1907286841099123\n",
      "train loss:0.9961459600527179\n",
      "train loss:0.9736153972796021\n",
      "train loss:1.0568427845071282\n",
      "train loss:1.157426214224026\n",
      "train loss:1.1130243393042336\n",
      "train loss:1.0188766703417766\n",
      "train loss:1.1306508856567978\n",
      "train loss:1.131130627870973\n",
      "train loss:1.0825391430350664\n",
      "train loss:1.110355358996113\n",
      "train loss:1.0621723369379654\n",
      "train loss:1.211741130069194\n",
      "train loss:0.9847195473324899\n",
      "train loss:1.0565908045515242\n",
      "train loss:1.0479041035061136\n",
      "train loss:1.1949353911776455\n",
      "train loss:1.3469510393614184\n",
      "train loss:0.9475706988612441\n",
      "train loss:1.0514684146280548\n",
      "train loss:0.9446588228176741\n",
      "train loss:1.077851080447047\n",
      "train loss:1.1022665818713053\n",
      "train loss:1.2373408347156187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.2152670772603107\n",
      "train loss:1.1690235105889133\n",
      "train loss:0.986066075237417\n",
      "train loss:0.9845256210331407\n",
      "train loss:1.2162241030759333\n",
      "train loss:1.2040727282142207\n",
      "train loss:1.0731416383290797\n",
      "train loss:1.0824083219183387\n",
      "train loss:1.2193788691237557\n",
      "train loss:1.1657770218427808\n",
      "train loss:1.1722512284918667\n",
      "train loss:1.0310889284123375\n",
      "train loss:0.9629806601136471\n",
      "train loss:1.082808821938845\n",
      "train loss:1.0580450996596755\n",
      "train loss:1.1721438495709382\n",
      "train loss:1.1241916596692452\n",
      "train loss:0.9743558477311646\n",
      "train loss:1.145630194797731\n",
      "train loss:1.2640694276001077\n",
      "train loss:1.183998212658507\n",
      "train loss:1.1661624841771512\n",
      "train loss:1.065863127442283\n",
      "train loss:1.2183216630236389\n",
      "train loss:1.05830876973909\n",
      "train loss:1.4191173124010943\n",
      "train loss:1.1041475121048103\n",
      "train loss:1.188143615079584\n",
      "train loss:1.0160515950891258\n",
      "train loss:1.0797528037354576\n",
      "train loss:1.0820257574928265\n",
      "train loss:1.1341833675190116\n",
      "train loss:1.0453218103680646\n",
      "train loss:1.1299491957221444\n",
      "train loss:1.152205158206969\n",
      "train loss:1.0559889573544323\n",
      "train loss:1.0118912902807196\n",
      "train loss:1.139533802836162\n",
      "train loss:1.2049721342656108\n",
      "train loss:0.9959202838780825\n",
      "train loss:1.003036955466312\n",
      "train loss:0.9220993970657315\n",
      "train loss:1.0513719844782172\n",
      "train loss:0.9220955991461335\n",
      "train loss:1.2660601887839555\n",
      "train loss:1.1306864422467597\n",
      "train loss:1.1611711041745294\n",
      "train loss:1.2091207717953585\n",
      "train loss:1.093074560288123\n",
      "train loss:1.118126370781152\n",
      "train loss:1.3025518418123625\n",
      "train loss:1.2085881731992976\n",
      "train loss:0.9978195027560218\n",
      "train loss:1.2335421548697507\n",
      "train loss:0.9804674671070083\n",
      "train loss:1.1254901129650137\n",
      "train loss:1.2009377537943622\n",
      "train loss:1.0846675813538058\n",
      "train loss:1.1750684504420874\n",
      "train loss:1.1568924501845828\n",
      "train loss:1.0849022727037552\n",
      "train loss:1.0126850865384394\n",
      "train loss:1.1049712892435917\n",
      "train loss:1.1363566653027348\n",
      "train loss:1.1315109294759316\n",
      "train loss:0.89092790302401\n",
      "train loss:0.9160237728068223\n",
      "train loss:1.0752437828232395\n",
      "train loss:1.1932449869794852\n",
      "train loss:1.036042086372512\n",
      "train loss:1.0503869863679338\n",
      "train loss:1.1333369087902938\n",
      "train loss:1.2961438998285937\n",
      "train loss:1.0383443942579078\n",
      "train loss:1.1410390676067097\n",
      "train loss:1.1438616865082833\n",
      "train loss:1.037461836570826\n",
      "train loss:0.891960222972014\n",
      "train loss:1.0939428072356063\n",
      "train loss:1.1699146628071788\n",
      "train loss:0.8221873314468253\n",
      "train loss:0.955137486792743\n",
      "train loss:1.2563155004029076\n",
      "train loss:1.1573821046179151\n",
      "train loss:1.0902579162043589\n",
      "train loss:1.0064265092905287\n",
      "train loss:1.0947799282603652\n",
      "train loss:0.9141526519857155\n",
      "train loss:1.0958957051907248\n",
      "train loss:1.1397549068379367\n",
      "train loss:1.1155781571453651\n",
      "train loss:1.0553755633436268\n",
      "train loss:1.1840741923102192\n",
      "train loss:1.074145172304782\n",
      "train loss:0.8705549883352879\n",
      "train loss:1.0917018281261492\n",
      "train loss:1.0546295729186266\n",
      "train loss:1.0044312237039623\n",
      "train loss:0.9848648854772948\n",
      "train loss:1.1790453601906514\n",
      "train loss:0.8298781410525023\n",
      "train loss:1.0017386124792755\n",
      "train loss:1.139920254474367\n",
      "train loss:0.9096396023315612\n",
      "train loss:0.9618658583876359\n",
      "train loss:1.002716135983312\n",
      "train loss:0.8552915999985072\n",
      "train loss:0.8559644612272902\n",
      "train loss:0.8505729392082619\n",
      "train loss:1.0216912340766295\n",
      "train loss:1.2166723944354612\n",
      "train loss:0.9493639571618041\n",
      "train loss:0.9382949721866954\n",
      "train loss:1.2163385925144758\n",
      "train loss:1.158997352929059\n",
      "train loss:0.9852865288062188\n",
      "train loss:1.057146395499984\n",
      "train loss:0.9728833267839235\n",
      "train loss:1.2508186174790636\n",
      "train loss:1.1512619035341798\n",
      "train loss:1.0585240750742555\n",
      "train loss:0.9987109714680094\n",
      "train loss:0.9980777094443867\n",
      "train loss:0.9903880503356832\n",
      "train loss:1.131518250366785\n",
      "train loss:0.8987034221534823\n",
      "train loss:0.9762775404988944\n",
      "train loss:1.1868466083108193\n",
      "train loss:1.2110796622517026\n",
      "train loss:1.167305555504166\n",
      "train loss:0.9792522649599975\n",
      "train loss:1.179199439077594\n",
      "train loss:0.8587935205197276\n",
      "train loss:0.9204774492854044\n",
      "train loss:1.0815502105773818\n",
      "train loss:0.986829432368807\n",
      "train loss:1.0154144650835364\n",
      "train loss:1.1504381464875655\n",
      "train loss:0.9649420534820073\n",
      "train loss:1.105822310271135\n",
      "train loss:1.2411576434361349\n",
      "train loss:1.0634813248643686\n",
      "train loss:0.818399412417824\n",
      "train loss:0.9857605266808345\n",
      "train loss:1.051939515752859\n",
      "train loss:1.068633523950353\n",
      "train loss:1.034314584970269\n",
      "train loss:1.0124029486611419\n",
      "train loss:0.9968917691430889\n",
      "train loss:1.1127656945719826\n",
      "train loss:1.1539740253066815\n",
      "train loss:1.1184019617839653\n",
      "train loss:1.130404269691728\n",
      "train loss:1.1486078734200489\n",
      "train loss:1.2838111973684176\n",
      "train loss:0.8769180239226182\n",
      "train loss:1.2013387410518979\n",
      "train loss:0.985785388282688\n",
      "train loss:0.9675285597447634\n",
      "train loss:1.025244367902873\n",
      "train loss:1.105179081611733\n",
      "train loss:1.1564698364545607\n",
      "train loss:1.0336825986542781\n",
      "train loss:1.1495207110090602\n",
      "train loss:0.9973684900095796\n",
      "train loss:1.0246383842715143\n",
      "train loss:1.144643117979876\n",
      "train loss:1.1142395366761655\n",
      "train loss:1.0066619422035286\n",
      "train loss:1.0026754319219657\n",
      "train loss:1.1219148550297895\n",
      "train loss:0.993436738753066\n",
      "train loss:1.0554287366206174\n",
      "train loss:1.1955966469016845\n",
      "train loss:1.0813977831582502\n",
      "train loss:0.9771479431359144\n",
      "train loss:1.039759987056738\n",
      "train loss:0.9937114094540703\n",
      "train loss:1.1108332745430496\n",
      "train loss:1.0995139647351408\n",
      "train loss:0.9042586468937871\n",
      "train loss:1.1763889690923648\n",
      "train loss:1.0231006495506896\n",
      "train loss:1.0075186213499525\n",
      "train loss:0.9214819567978044\n",
      "train loss:1.0512468145423166\n",
      "train loss:0.98456706624812\n",
      "train loss:0.9387586341049355\n",
      "train loss:0.7923140221918819\n",
      "train loss:1.0084859829165755\n",
      "train loss:0.8893868002224866\n",
      "train loss:1.0282500135713644\n",
      "train loss:0.8067052958474896\n",
      "train loss:0.9852966675203078\n",
      "train loss:0.9837096680367715\n",
      "train loss:1.0217654064930966\n",
      "train loss:1.0001591514619999\n",
      "train loss:1.040688929452492\n",
      "train loss:0.9316129778712064\n",
      "train loss:1.1777899147213464\n",
      "train loss:1.081298929043892\n",
      "train loss:0.9367867141637914\n",
      "train loss:0.7580339395931055\n",
      "train loss:1.0004622359421977\n",
      "train loss:1.1399397694329163\n",
      "train loss:1.0568766014198707\n",
      "train loss:1.1355330470618348\n",
      "train loss:1.0442430369724667\n",
      "train loss:1.0672418471367553\n",
      "train loss:1.1361694326004617\n",
      "train loss:1.050654146231948\n",
      "train loss:0.9191714380529306\n",
      "train loss:1.0294297091890814\n",
      "train loss:0.9178039436871428\n",
      "train loss:0.8386320919224554\n",
      "train loss:1.0118734087524979\n",
      "train loss:0.9621385446632624\n",
      "train loss:1.1479580067181236\n",
      "train loss:1.072178302987448\n",
      "train loss:1.0876785534255502\n",
      "train loss:1.0698854310951191\n",
      "train loss:1.048741159133771\n",
      "train loss:0.964832098265293\n",
      "train loss:1.052033761984268\n",
      "train loss:0.9819352949436674\n",
      "train loss:0.9979294689184931\n",
      "train loss:1.2728669442496092\n",
      "train loss:1.1193075736483968\n",
      "train loss:0.9604675862290801\n",
      "train loss:0.9662722640842095\n",
      "train loss:0.9085225328749504\n",
      "train loss:0.9709750404851217\n",
      "train loss:1.0750270732923422\n",
      "train loss:0.9992345006405968\n",
      "train loss:0.9171654727791495\n",
      "train loss:1.0381445858853824\n",
      "train loss:1.0780911824893724\n",
      "train loss:0.9514924929978075\n",
      "train loss:1.0042652842757434\n",
      "train loss:1.1225502763791937\n",
      "train loss:1.1532697602877304\n",
      "train loss:1.133903599697321\n",
      "train loss:1.0444187402711458\n",
      "train loss:1.0292459002155312\n",
      "train loss:1.1175049452260146\n",
      "train loss:0.955320716266475\n",
      "train loss:1.107085521745714\n",
      "train loss:0.9943394770194502\n",
      "train loss:0.9057654995272405\n",
      "train loss:0.9494322667450418\n",
      "train loss:0.961617359788628\n",
      "train loss:0.9015311115096176\n",
      "train loss:0.8763567993988503\n",
      "train loss:1.2645613206295356\n",
      "train loss:0.9658923341899113\n",
      "train loss:1.024595120279744\n",
      "train loss:1.168014129377442\n",
      "train loss:0.9335169216928897\n",
      "train loss:0.9242262166294789\n",
      "train loss:1.0514940736313898\n",
      "train loss:1.1630894747130316\n",
      "train loss:0.9448928402967514\n",
      "train loss:0.9906436445791647\n",
      "train loss:1.0464811656073707\n",
      "train loss:1.0165718932205605\n",
      "train loss:0.9415719730084957\n",
      "train loss:1.0267220848752254\n",
      "train loss:0.9267114184378216\n",
      "train loss:0.913735157769146\n",
      "train loss:1.0552554665342317\n",
      "train loss:1.092170550262545\n",
      "train loss:1.0542887432068988\n",
      "train loss:1.0573532031989494\n",
      "train loss:1.023132092836544\n",
      "train loss:0.9140046004053646\n",
      "train loss:1.276250067097957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.9169226076398332\n",
      "train loss:0.9692592797090974\n",
      "train loss:1.0460810703892223\n",
      "train loss:1.0392538020280684\n",
      "train loss:0.9234219926178844\n",
      "train loss:1.0355595278388885\n",
      "train loss:0.988874323136687\n",
      "train loss:1.092597381582163\n",
      "train loss:1.0194896148169956\n",
      "train loss:0.8094932218261991\n",
      "train loss:1.125969598157652\n",
      "train loss:1.0403074450369199\n",
      "train loss:1.061437679483508\n",
      "train loss:0.9606259803464359\n",
      "train loss:0.9146098068448318\n",
      "train loss:1.1475185668107037\n",
      "train loss:1.039225433265175\n",
      "train loss:1.0156442083369845\n",
      "train loss:1.0176138638519228\n",
      "train loss:0.9873516383611485\n",
      "train loss:1.1982063871448134\n",
      "train loss:1.105204595249053\n",
      "train loss:1.1314265858567867\n",
      "train loss:1.0433207453556146\n",
      "train loss:0.9219174624383335\n",
      "train loss:1.0148690578667883\n",
      "train loss:1.1826661475898146\n",
      "train loss:0.9171661530344355\n",
      "train loss:1.1020892854078115\n",
      "train loss:0.9911490859411795\n",
      "train loss:1.0267249974375325\n",
      "train loss:1.0061588493948146\n",
      "train loss:1.0051580185086875\n",
      "train loss:1.29136313793247\n",
      "train loss:0.9610177204279432\n",
      "train loss:1.0420388408320538\n",
      "train loss:1.1454658983636168\n",
      "train loss:0.8772038023695756\n",
      "train loss:1.0370520046127634\n",
      "train loss:0.9532324263619502\n",
      "train loss:1.0570953064319328\n",
      "train loss:0.8842674897637349\n",
      "train loss:1.0803305645148602\n",
      "train loss:1.2572438029369655\n",
      "train loss:0.9531563201844588\n",
      "train loss:0.889596979801354\n",
      "train loss:0.9999125518110802\n",
      "train loss:0.7902425443610597\n",
      "train loss:1.0266388654169187\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.98\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from dataset.mnist import load_mnist\n",
    "from DeepLearning_deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=1, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(1)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
