{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3010503627824352\n",
      "=== epoch:1, train acc:0.222, test acc:0.254 ===\n",
      "train loss:2.3006947816028567\n",
      "train loss:2.3000194461672976\n",
      "train loss:2.2977283507705235\n",
      "train loss:2.2953291335388557\n",
      "train loss:2.2904727431534715\n",
      "train loss:2.2884171134527382\n",
      "train loss:2.284732300870087\n",
      "train loss:2.2739781329489204\n",
      "train loss:2.267031697173233\n",
      "train loss:2.251092504901537\n",
      "train loss:2.242577775114964\n",
      "train loss:2.228320369344183\n",
      "train loss:2.215209122263545\n",
      "train loss:2.209821548384016\n",
      "train loss:2.147247732262591\n",
      "train loss:2.105137758816693\n",
      "train loss:2.106262516067113\n",
      "train loss:2.079271713000978\n",
      "train loss:2.059627772938257\n",
      "train loss:2.0022928252947936\n",
      "train loss:1.9954767833941884\n",
      "train loss:1.9771044558510338\n",
      "train loss:1.842092963168756\n",
      "train loss:1.7711063971221677\n",
      "train loss:1.8187583370706708\n",
      "train loss:1.7101813274630289\n",
      "train loss:1.7303625629449315\n",
      "train loss:1.5797892729896372\n",
      "train loss:1.483677473735747\n",
      "train loss:1.476767663859733\n",
      "train loss:1.4017546173862487\n",
      "train loss:1.3604767501226263\n",
      "train loss:1.2030861360851517\n",
      "train loss:1.2191828361217172\n",
      "train loss:1.080411671167539\n",
      "train loss:1.12457298372877\n",
      "train loss:1.2201750424766558\n",
      "train loss:1.0556843196239938\n",
      "train loss:0.9024191357949402\n",
      "train loss:0.8191287588018562\n",
      "train loss:0.9070580848730134\n",
      "train loss:0.8489561095550335\n",
      "train loss:0.8221186859379204\n",
      "train loss:0.7739721180052961\n",
      "train loss:0.7754924375811121\n",
      "train loss:0.9009075967176929\n",
      "train loss:0.8086442270279265\n",
      "train loss:0.624630128549256\n",
      "train loss:0.8637294018784003\n",
      "train loss:0.7425989979087413\n",
      "train loss:0.8614531220674152\n",
      "train loss:0.6921728335237721\n",
      "train loss:0.48181519261866185\n",
      "train loss:0.6524518000182776\n",
      "train loss:0.7282314250484332\n",
      "train loss:0.9316627103441943\n",
      "train loss:0.6737134116529636\n",
      "train loss:0.6276463366601455\n",
      "train loss:0.5716250600798264\n",
      "train loss:0.6390090453215469\n",
      "train loss:0.47901343841005983\n",
      "train loss:0.6049690650999633\n",
      "train loss:0.5355718889748231\n",
      "train loss:0.4638504163633997\n",
      "train loss:0.665877767585459\n",
      "train loss:0.5013040013455987\n",
      "train loss:0.47867262244429204\n",
      "train loss:0.546254947140265\n",
      "train loss:0.5704673574654291\n",
      "train loss:0.7263615850127055\n",
      "train loss:0.5796424569581783\n",
      "train loss:0.5527843405684199\n",
      "train loss:0.5446322157322809\n",
      "train loss:0.7042791209628512\n",
      "train loss:0.6001642394117549\n",
      "train loss:0.5191216632606731\n",
      "train loss:0.5588203491518093\n",
      "train loss:0.5108077759952581\n",
      "train loss:0.4804105617370258\n",
      "train loss:0.5690819029427504\n",
      "train loss:0.5638411625830949\n",
      "train loss:0.4387964969729984\n",
      "train loss:0.5270616078752483\n",
      "train loss:0.48661908081000427\n",
      "train loss:0.3927764422889812\n",
      "train loss:0.45918289740253426\n",
      "train loss:0.39770509457602643\n",
      "train loss:0.4433725699406723\n",
      "train loss:0.6778579188550546\n",
      "train loss:0.6035253179946461\n",
      "train loss:0.3891209467420773\n",
      "train loss:0.32760225323192665\n",
      "train loss:0.6468504455541085\n",
      "train loss:0.4541725854987625\n",
      "train loss:0.36589181632014445\n",
      "train loss:0.4519377693944898\n",
      "train loss:0.5151666679922281\n",
      "train loss:0.46213968721658794\n",
      "train loss:0.8116064585138735\n",
      "train loss:0.5581297532271031\n",
      "train loss:0.3764689217426791\n",
      "train loss:0.4972615425681158\n",
      "train loss:0.34350961803285657\n",
      "train loss:0.3342762504775865\n",
      "train loss:0.33564614024445383\n",
      "train loss:0.4219193039867832\n",
      "train loss:0.4219498156816095\n",
      "train loss:0.42047589326996404\n",
      "train loss:0.55772397505921\n",
      "train loss:0.37139237994844165\n",
      "train loss:0.3928846347994994\n",
      "train loss:0.6042431496288383\n",
      "train loss:0.3676534725783383\n",
      "train loss:0.543894922474007\n",
      "train loss:0.3922476135710702\n",
      "train loss:0.3637021021582494\n",
      "train loss:0.4906030712809902\n",
      "train loss:0.5059798767664039\n",
      "train loss:0.34371408873753473\n",
      "train loss:0.48642262988108165\n",
      "train loss:0.2629501893024779\n",
      "train loss:0.43316469619515474\n",
      "train loss:0.406147444636067\n",
      "train loss:0.42860097394604835\n",
      "train loss:0.46855908070183083\n",
      "train loss:0.33302052251538256\n",
      "train loss:0.4505651068742651\n",
      "train loss:0.5005920935043331\n",
      "train loss:0.47653204535096555\n",
      "train loss:0.3159534903777608\n",
      "train loss:0.40751185132720635\n",
      "train loss:0.37501613879985113\n",
      "train loss:0.5037452253490803\n",
      "train loss:0.35166142805876127\n",
      "train loss:0.5335579443747479\n",
      "train loss:0.41028429899544344\n",
      "train loss:0.34069700097643074\n",
      "train loss:0.30921543312154354\n",
      "train loss:0.39139342140768185\n",
      "train loss:0.47935745694008314\n",
      "train loss:0.437693731604158\n",
      "train loss:0.24858440539802615\n",
      "train loss:0.34275301783025747\n",
      "train loss:0.3959281748539716\n",
      "train loss:0.4414864506785833\n",
      "train loss:0.4514111207149095\n",
      "train loss:0.39850183422386853\n",
      "train loss:0.40125191922403103\n",
      "train loss:0.21394995988074694\n",
      "train loss:0.26438467412016897\n",
      "train loss:0.3834570645687856\n",
      "train loss:0.2762573789007984\n",
      "train loss:0.365155453577338\n",
      "train loss:0.3365101457924262\n",
      "train loss:0.28374730166892287\n",
      "train loss:0.5044615083211831\n",
      "train loss:0.29866735808381956\n",
      "train loss:0.43832499635239214\n",
      "train loss:0.4328538829273853\n",
      "train loss:0.29619290340322985\n",
      "train loss:0.3719538260256481\n",
      "train loss:0.3744520147979346\n",
      "train loss:0.4942884415848494\n",
      "train loss:0.3308607561080772\n",
      "train loss:0.40442985616406846\n",
      "train loss:0.41955806467982554\n",
      "train loss:0.3934383721691087\n",
      "train loss:0.31697426890977054\n",
      "train loss:0.2983897881693946\n",
      "train loss:0.2221540971990648\n",
      "train loss:0.3511664038225762\n",
      "train loss:0.41213146583478427\n",
      "train loss:0.4109197646316343\n",
      "train loss:0.49267367587205546\n",
      "train loss:0.3736707201425959\n",
      "train loss:0.4165512289281475\n",
      "train loss:0.41112508011156423\n",
      "train loss:0.41689795238785654\n",
      "train loss:0.35430305940066165\n",
      "train loss:0.43026584557822534\n",
      "train loss:0.36815142748737556\n",
      "train loss:0.5375332394321449\n",
      "train loss:0.2918489508997105\n",
      "train loss:0.3942395511076534\n",
      "train loss:0.3607107350593125\n",
      "train loss:0.31411958153346625\n",
      "train loss:0.25913152948138163\n",
      "train loss:0.5210186432394809\n",
      "train loss:0.2725394550415401\n",
      "train loss:0.3877353109861355\n",
      "train loss:0.38176523597057005\n",
      "train loss:0.2590368290632099\n",
      "train loss:0.22446751161030434\n",
      "train loss:0.27964965563526456\n",
      "train loss:0.27293576838892086\n",
      "train loss:0.4552069819707427\n",
      "train loss:0.27440774892957975\n",
      "train loss:0.3956350212082574\n",
      "train loss:0.5474957847545883\n",
      "train loss:0.326156437846126\n",
      "train loss:0.26570921610228954\n",
      "train loss:0.44964245970443484\n",
      "train loss:0.31738225000870696\n",
      "train loss:0.2231873398720232\n",
      "train loss:0.26312760327942125\n",
      "train loss:0.39671748711171445\n",
      "train loss:0.35310083485770904\n",
      "train loss:0.29272927589872383\n",
      "train loss:0.39824038686103796\n",
      "train loss:0.21073180958761117\n",
      "train loss:0.38985745992218734\n",
      "train loss:0.38414320633413224\n",
      "train loss:0.254261047466362\n",
      "train loss:0.3380417103288222\n",
      "train loss:0.2260281129508065\n",
      "train loss:0.3422698308005382\n",
      "train loss:0.3367135065547467\n",
      "train loss:0.4691838354114312\n",
      "train loss:0.48632917161138367\n",
      "train loss:0.290968111516335\n",
      "train loss:0.3808758154169253\n",
      "train loss:0.45833746181155155\n",
      "train loss:0.33472021428279014\n",
      "train loss:0.382859957410892\n",
      "train loss:0.28632124265036263\n",
      "train loss:0.4101597051504232\n",
      "train loss:0.3826533150225081\n",
      "train loss:0.3078246550989097\n",
      "train loss:0.37079471292803995\n",
      "train loss:0.3405229876293876\n",
      "train loss:0.3684028530441274\n",
      "train loss:0.4257379879198501\n",
      "train loss:0.35409046370831804\n",
      "train loss:0.31698804309837214\n",
      "train loss:0.3499037918388488\n",
      "train loss:0.3700744331344506\n",
      "train loss:0.2850237123719426\n",
      "train loss:0.3157607848326085\n",
      "train loss:0.35155342229132047\n",
      "train loss:0.31700572742393573\n",
      "train loss:0.2915699564214763\n",
      "train loss:0.26226742287060195\n",
      "train loss:0.43695445737210975\n",
      "train loss:0.36956367653181404\n",
      "train loss:0.23361144729482777\n",
      "train loss:0.4330129050094314\n",
      "train loss:0.20362386730508192\n",
      "train loss:0.3790051710866608\n",
      "train loss:0.30849707241647434\n",
      "train loss:0.554530835863967\n",
      "train loss:0.22262360713705148\n",
      "train loss:0.2496879845768754\n",
      "train loss:0.44565338741711313\n",
      "train loss:0.34686180637503095\n",
      "train loss:0.3851650179930889\n",
      "train loss:0.2539808953713176\n",
      "train loss:0.27813625677742343\n",
      "train loss:0.39475928078916284\n",
      "train loss:0.4486576488948243\n",
      "train loss:0.362738388797999\n",
      "train loss:0.47591714369745963\n",
      "train loss:0.24750996893966842\n",
      "train loss:0.40023448573148535\n",
      "train loss:0.3387806489474478\n",
      "train loss:0.33089270888712946\n",
      "train loss:0.47612062861515986\n",
      "train loss:0.346360576348135\n",
      "train loss:0.4650300096262394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.45309924172773747\n",
      "train loss:0.2898688176457082\n",
      "train loss:0.2846689772673915\n",
      "train loss:0.32867248971410007\n",
      "train loss:0.27331201139470085\n",
      "train loss:0.39894982488338376\n",
      "train loss:0.37587849017981123\n",
      "train loss:0.1616407363392171\n",
      "train loss:0.37761621937057877\n",
      "train loss:0.4270738294755022\n",
      "train loss:0.24586475840099634\n",
      "train loss:0.3218882656074583\n",
      "train loss:0.31235743368904995\n",
      "train loss:0.1332874636208445\n",
      "train loss:0.3409437003236423\n",
      "train loss:0.34589710961787873\n",
      "train loss:0.3861404280341392\n",
      "train loss:0.2755144713313997\n",
      "train loss:0.22030908827092793\n",
      "train loss:0.3067930557740395\n",
      "train loss:0.36010483476990346\n",
      "train loss:0.35131593368611974\n",
      "train loss:0.3057275101835462\n",
      "train loss:0.2805112623664381\n",
      "train loss:0.2946755074056725\n",
      "train loss:0.33315872545411274\n",
      "train loss:0.23531105475275146\n",
      "train loss:0.20106813121983225\n",
      "train loss:0.34783223823245185\n",
      "train loss:0.33048735035863125\n",
      "train loss:0.2210800573083211\n",
      "train loss:0.3816553090069963\n",
      "train loss:0.3030987991603495\n",
      "train loss:0.33594024967485964\n",
      "train loss:0.4503355244201004\n",
      "train loss:0.307407088058547\n",
      "train loss:0.4823759336807508\n",
      "train loss:0.2661151163264322\n",
      "train loss:0.2922369584200456\n",
      "train loss:0.44951550542913354\n",
      "train loss:0.22684421476891198\n",
      "train loss:0.23746559768441705\n",
      "train loss:0.33423094218153726\n",
      "train loss:0.31663468246876153\n",
      "train loss:0.29963733157833666\n",
      "train loss:0.38115206492032777\n",
      "train loss:0.3544106387541919\n",
      "train loss:0.23071099614920126\n",
      "train loss:0.4195664337474055\n",
      "train loss:0.3704441435534433\n",
      "train loss:0.3807766741597678\n",
      "train loss:0.3884212418928349\n",
      "train loss:0.23527376242480247\n",
      "train loss:0.16036580586097432\n",
      "train loss:0.5792398135349177\n",
      "train loss:0.2043369632955897\n",
      "train loss:0.20466789012676131\n",
      "train loss:0.37859385260226913\n",
      "train loss:0.27854697989057886\n",
      "train loss:0.3112200186393542\n",
      "train loss:0.31860581881646605\n",
      "train loss:0.314396844927893\n",
      "train loss:0.4240091852360276\n",
      "train loss:0.2544647995473977\n",
      "train loss:0.2520295782063134\n",
      "train loss:0.41960107031680033\n",
      "train loss:0.2525530158460252\n",
      "train loss:0.26786370224291317\n",
      "train loss:0.3395795093030912\n",
      "train loss:0.27891734052457706\n",
      "train loss:0.29288193657625794\n",
      "train loss:0.2464396246723096\n",
      "train loss:0.3095907839036295\n",
      "train loss:0.2722419789873212\n",
      "train loss:0.1879883413946524\n",
      "train loss:0.15933470830764696\n",
      "train loss:0.24054839077159987\n",
      "train loss:0.18961396235397904\n",
      "train loss:0.293278936225376\n",
      "train loss:0.3055059845204331\n",
      "train loss:0.14195498752386077\n",
      "train loss:0.3833345035145277\n",
      "train loss:0.22915730246011914\n",
      "train loss:0.27534415964215775\n",
      "train loss:0.19468325350173227\n",
      "train loss:0.22561268652624833\n",
      "train loss:0.30319988980088547\n",
      "train loss:0.29172098071854063\n",
      "train loss:0.21642605661851871\n",
      "train loss:0.6059609570813174\n",
      "train loss:0.27040908530733543\n",
      "train loss:0.21791199234130387\n",
      "train loss:0.2760866084138783\n",
      "train loss:0.30933778714888727\n",
      "train loss:0.15965868780467343\n",
      "train loss:0.24352727898504833\n",
      "train loss:0.4211115161374926\n",
      "train loss:0.3146655015263598\n",
      "train loss:0.32637051739754774\n",
      "train loss:0.3252204349770062\n",
      "train loss:0.23769218926340188\n",
      "train loss:0.22138943204550263\n",
      "train loss:0.3135118897434427\n",
      "train loss:0.3803051266395742\n",
      "train loss:0.24928325393918546\n",
      "train loss:0.2946864357660643\n",
      "train loss:0.2377656921505985\n",
      "train loss:0.21552780144462408\n",
      "train loss:0.2403358575372815\n",
      "train loss:0.3707788691894644\n",
      "train loss:0.23526980365964623\n",
      "train loss:0.28512452275905864\n",
      "train loss:0.4327909748381378\n",
      "train loss:0.23965708708351688\n",
      "train loss:0.26959425064798487\n",
      "train loss:0.2745307838586362\n",
      "train loss:0.277246288036238\n",
      "train loss:0.1577216223358343\n",
      "train loss:0.3041933995270164\n",
      "train loss:0.41586865812609725\n",
      "train loss:0.27376369409197937\n",
      "train loss:0.38643389505734227\n",
      "train loss:0.2682958709793705\n",
      "train loss:0.33464835709873664\n",
      "train loss:0.27244243792651984\n",
      "train loss:0.27763089312848604\n",
      "train loss:0.29020330888035367\n",
      "train loss:0.15346879991060347\n",
      "train loss:0.13902334540819683\n",
      "train loss:0.27368950527897906\n",
      "train loss:0.24419528947773056\n",
      "train loss:0.10015465491996163\n",
      "train loss:0.30034415470798786\n",
      "train loss:0.26987276398471066\n",
      "train loss:0.26754517300118147\n",
      "train loss:0.22039826998617143\n",
      "train loss:0.3252835516208634\n",
      "train loss:0.20826893580866354\n",
      "train loss:0.27134948215446375\n",
      "train loss:0.43436945976392854\n",
      "train loss:0.280018835766284\n",
      "train loss:0.2861800352789491\n",
      "train loss:0.2641114862552236\n",
      "train loss:0.22914845288049637\n",
      "train loss:0.2902769950065386\n",
      "train loss:0.23003358391446382\n",
      "train loss:0.3246833863343418\n",
      "train loss:0.3173638137649182\n",
      "train loss:0.24114037109211808\n",
      "train loss:0.19204815540232187\n",
      "train loss:0.24175691828268572\n",
      "train loss:0.374991749639463\n",
      "train loss:0.1831065951876753\n",
      "train loss:0.2543655461469411\n",
      "train loss:0.21357455717697862\n",
      "train loss:0.2394136179199173\n",
      "train loss:0.2435017712855137\n",
      "train loss:0.22699845182753542\n",
      "train loss:0.27013572353307347\n",
      "train loss:0.3384327520894314\n",
      "train loss:0.3251746088240997\n",
      "train loss:0.2020561308464236\n",
      "train loss:0.163015190947518\n",
      "train loss:0.2417116137090898\n",
      "train loss:0.10635820054602453\n",
      "train loss:0.2473765077967229\n",
      "train loss:0.25746345040665375\n",
      "train loss:0.18665731558148946\n",
      "train loss:0.1961766230569244\n",
      "train loss:0.15103712661311516\n",
      "train loss:0.4380374132403061\n",
      "train loss:0.16233296259932384\n",
      "train loss:0.31118962308092457\n",
      "train loss:0.19102743974363112\n",
      "train loss:0.30481369526668933\n",
      "train loss:0.22167977147638038\n",
      "train loss:0.190612154983643\n",
      "train loss:0.22477775787924936\n",
      "train loss:0.14995063658517338\n",
      "train loss:0.24491875899024199\n",
      "train loss:0.28046278642496936\n",
      "train loss:0.2644063356370697\n",
      "train loss:0.2891573613981656\n",
      "train loss:0.2734165446426398\n",
      "train loss:0.3353781083899547\n",
      "train loss:0.14675286368599083\n",
      "train loss:0.24074205491860837\n",
      "train loss:0.2166512140944988\n",
      "train loss:0.3979380536511645\n",
      "train loss:0.19495870222103404\n",
      "train loss:0.2667650144124219\n",
      "train loss:0.18571764802277888\n",
      "train loss:0.21023022310989226\n",
      "train loss:0.11491990359908925\n",
      "train loss:0.2716728149485609\n",
      "train loss:0.1929724919979459\n",
      "train loss:0.31520271220184015\n",
      "train loss:0.2326909642285074\n",
      "train loss:0.1974822258345637\n",
      "train loss:0.3918814239480152\n",
      "train loss:0.2969589067363279\n",
      "train loss:0.2041531866669594\n",
      "train loss:0.11926868412599635\n",
      "train loss:0.13688236958652567\n",
      "train loss:0.16242122208713\n",
      "train loss:0.1812730319018543\n",
      "train loss:0.2405648243899847\n",
      "train loss:0.21944006768533764\n",
      "train loss:0.29690823146791834\n",
      "train loss:0.10798536338056315\n",
      "train loss:0.2237307389469581\n",
      "train loss:0.273098156374827\n",
      "train loss:0.25617954175245666\n",
      "train loss:0.22988104354099625\n",
      "train loss:0.28841321377561335\n",
      "train loss:0.29273847958243915\n",
      "train loss:0.15689805123029946\n",
      "train loss:0.1740860225774644\n",
      "train loss:0.18882449701928752\n",
      "train loss:0.24639641564745599\n",
      "train loss:0.4465370051691127\n",
      "train loss:0.14608699054587881\n",
      "train loss:0.2350169664157962\n",
      "train loss:0.24297311470736602\n",
      "train loss:0.2496553028593434\n",
      "train loss:0.15784271236790226\n",
      "train loss:0.2613920030488479\n",
      "train loss:0.3355452364575329\n",
      "train loss:0.25858349907420264\n",
      "train loss:0.2838629833724829\n",
      "train loss:0.16413857392517056\n",
      "train loss:0.08418986510716588\n",
      "train loss:0.08677055107350715\n",
      "train loss:0.2774655112681113\n",
      "train loss:0.20445946314257754\n",
      "train loss:0.20846358144869645\n",
      "train loss:0.15848452437144858\n",
      "train loss:0.16640665043960123\n",
      "train loss:0.16516836245877617\n",
      "train loss:0.15489470195471527\n",
      "train loss:0.17084967338268936\n",
      "train loss:0.24156427133971353\n",
      "train loss:0.1688132044852668\n",
      "train loss:0.24699506902946056\n",
      "train loss:0.24407212960838695\n",
      "train loss:0.36472122675910845\n",
      "train loss:0.17600426262761812\n",
      "train loss:0.16875227212181187\n",
      "train loss:0.16297446393901857\n",
      "train loss:0.34176892164854583\n",
      "train loss:0.1808328526381507\n",
      "train loss:0.17507643981609852\n",
      "train loss:0.21041645551634847\n",
      "train loss:0.24223433514193363\n",
      "train loss:0.27444392551103314\n",
      "train loss:0.2773935450583764\n",
      "train loss:0.3657422595955018\n",
      "train loss:0.2918647232798912\n",
      "train loss:0.09253695194066322\n",
      "train loss:0.22229007477296972\n",
      "train loss:0.3224587151737009\n",
      "train loss:0.25551082063559877\n",
      "train loss:0.1896316533061885\n",
      "train loss:0.1634047280622888\n",
      "train loss:0.28033297876954716\n",
      "train loss:0.14419010949595792\n",
      "train loss:0.1716835275767729\n",
      "train loss:0.16523295873431626\n",
      "train loss:0.31831805294843973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.16789228230365033\n",
      "train loss:0.09961734091837822\n",
      "train loss:0.15115222797151465\n",
      "train loss:0.27628442980854345\n",
      "train loss:0.3220287078032763\n",
      "train loss:0.1580787048502163\n",
      "train loss:0.1658454755055191\n",
      "train loss:0.29439524246563914\n",
      "train loss:0.1630308666115154\n",
      "train loss:0.28946872783169836\n",
      "train loss:0.18283850731475035\n",
      "train loss:0.16745432996672172\n",
      "train loss:0.22099580413660402\n",
      "train loss:0.17940475967456035\n",
      "train loss:0.19225612601032896\n",
      "train loss:0.2615860185092893\n",
      "train loss:0.14825989354943483\n",
      "train loss:0.21008361742504408\n",
      "train loss:0.21340706450038105\n",
      "train loss:0.14461553519360815\n",
      "train loss:0.17961938554371465\n",
      "train loss:0.2026817662870823\n",
      "train loss:0.1261507016298473\n",
      "train loss:0.14952940231875153\n",
      "train loss:0.25580939083176224\n",
      "train loss:0.12376916173734172\n",
      "train loss:0.1576857721055682\n",
      "train loss:0.2609759021572107\n",
      "train loss:0.19869246389804385\n",
      "train loss:0.1832844399960939\n",
      "train loss:0.26605931139531375\n",
      "train loss:0.17166763565031798\n",
      "train loss:0.18788603605068807\n",
      "train loss:0.16343636427245684\n",
      "train loss:0.19370661437510275\n",
      "train loss:0.15281741692783624\n",
      "train loss:0.2719873619636094\n",
      "train loss:0.18552243549378847\n",
      "train loss:0.19858888311829356\n",
      "train loss:0.12174992763686011\n",
      "train loss:0.21633384461271482\n",
      "train loss:0.1619387727386068\n",
      "train loss:0.1468015128924197\n",
      "train loss:0.16101882255746924\n",
      "train loss:0.16698470776545368\n",
      "train loss:0.2690378197110929\n",
      "train loss:0.22219963277317945\n",
      "train loss:0.21925069465712357\n",
      "train loss:0.09765161480199451\n",
      "train loss:0.1265402694397485\n",
      "train loss:0.22074702029297735\n",
      "train loss:0.20923161271252422\n",
      "train loss:0.17536466400514655\n",
      "train loss:0.2783408829452983\n",
      "train loss:0.2376688653084826\n",
      "train loss:0.205153663429815\n",
      "train loss:0.27550346771001194\n",
      "train loss:0.1378044539281794\n",
      "train loss:0.5342695272490453\n",
      "train loss:0.14659452368918946\n",
      "train loss:0.20006981699601817\n",
      "train loss:0.12114554892238827\n",
      "train loss:0.23645151604819717\n",
      "=== epoch:2, train acc:0.938, test acc:0.943 ===\n",
      "train loss:0.34161245000217505\n",
      "train loss:0.14559280563931323\n",
      "train loss:0.13373922645666464\n",
      "train loss:0.09132748289184801\n",
      "train loss:0.18144884761057337\n",
      "train loss:0.11133984818333548\n",
      "train loss:0.15894783663801665\n",
      "train loss:0.10790144829621187\n",
      "train loss:0.21084230208842394\n",
      "train loss:0.10520606730856422\n",
      "train loss:0.16253092130472996\n",
      "train loss:0.20751802727289956\n",
      "train loss:0.2347842849098819\n",
      "train loss:0.18810124370388095\n",
      "train loss:0.09997767778934435\n",
      "train loss:0.11090735606974833\n",
      "train loss:0.21622293404109658\n",
      "train loss:0.11116407738511774\n",
      "train loss:0.24160183158063336\n",
      "train loss:0.267298065058436\n",
      "train loss:0.26292895537439565\n",
      "train loss:0.19256598791208596\n",
      "train loss:0.24009825483015748\n",
      "train loss:0.20871712328351408\n",
      "train loss:0.3074482410447915\n",
      "train loss:0.06113819140769621\n",
      "train loss:0.1517579184068005\n",
      "train loss:0.2583084783539877\n",
      "train loss:0.08028263831423722\n",
      "train loss:0.15131697278929815\n",
      "train loss:0.2844955639624283\n",
      "train loss:0.18488237522242762\n",
      "train loss:0.07588442189415312\n",
      "train loss:0.10786983466085241\n",
      "train loss:0.23628177627640706\n",
      "train loss:0.1537446322282046\n",
      "train loss:0.2225481136324296\n",
      "train loss:0.3149908738409018\n",
      "train loss:0.1540239534360036\n",
      "train loss:0.08146384822062598\n",
      "train loss:0.12087365438423067\n",
      "train loss:0.11086301017824392\n",
      "train loss:0.1545002111213987\n",
      "train loss:0.24501331890417513\n",
      "train loss:0.19902212767929067\n",
      "train loss:0.2291728782421949\n",
      "train loss:0.2131170901109605\n",
      "train loss:0.1929942819111166\n",
      "train loss:0.11611065753682297\n",
      "train loss:0.285793816823227\n",
      "train loss:0.2559423778581725\n",
      "train loss:0.18116168462286558\n",
      "train loss:0.17840741971752574\n",
      "train loss:0.23910833891185135\n",
      "train loss:0.14929177382976205\n",
      "train loss:0.1601048710000552\n",
      "train loss:0.16682702856084258\n",
      "train loss:0.2489287341832779\n",
      "train loss:0.2563192398010381\n",
      "train loss:0.084832811074268\n",
      "train loss:0.1579837099583142\n",
      "train loss:0.2203520143120982\n",
      "train loss:0.1069343883964817\n",
      "train loss:0.11358842255839288\n",
      "train loss:0.11737553312819995\n",
      "train loss:0.1960531912546254\n",
      "train loss:0.1668447805959261\n",
      "train loss:0.22492893983995763\n",
      "train loss:0.15218783064824573\n",
      "train loss:0.09562176180678933\n",
      "train loss:0.1537406659708872\n",
      "train loss:0.19648175555930827\n",
      "train loss:0.19716982680728365\n",
      "train loss:0.1661701010402863\n",
      "train loss:0.1068059340159264\n",
      "train loss:0.20796525100279484\n",
      "train loss:0.10502138906091191\n",
      "train loss:0.15983930027883173\n",
      "train loss:0.16532741006981386\n",
      "train loss:0.25724470830125173\n",
      "train loss:0.10600925566197689\n",
      "train loss:0.12248039325665865\n",
      "train loss:0.15865538964389425\n",
      "train loss:0.19238719006350039\n",
      "train loss:0.086066637568732\n",
      "train loss:0.14958550772084245\n",
      "train loss:0.1644647214193305\n",
      "train loss:0.13273886105587154\n",
      "train loss:0.12885556733243914\n",
      "train loss:0.1440686237035373\n",
      "train loss:0.13330200969838563\n",
      "train loss:0.13059993083990631\n",
      "train loss:0.15259241965284467\n",
      "train loss:0.13688245038053676\n",
      "train loss:0.18521997740748616\n",
      "train loss:0.14774407227770248\n",
      "train loss:0.11829376955259147\n",
      "train loss:0.1979363364613467\n",
      "train loss:0.11739247008794931\n",
      "train loss:0.08896229998673036\n",
      "train loss:0.15605478810805856\n",
      "train loss:0.19519161169667487\n",
      "train loss:0.0894507867193386\n",
      "train loss:0.18514411341138534\n",
      "train loss:0.18194235796193323\n",
      "train loss:0.2569695861093633\n",
      "train loss:0.08327422247270155\n",
      "train loss:0.20878715316696156\n",
      "train loss:0.11620482850656025\n",
      "train loss:0.1460634155858494\n",
      "train loss:0.142596130810256\n",
      "train loss:0.1851591462005459\n",
      "train loss:0.2659973504706744\n",
      "train loss:0.1885399144372447\n",
      "train loss:0.1507468245256171\n",
      "train loss:0.17821723508614565\n",
      "train loss:0.15592684268394513\n",
      "train loss:0.1697974686867127\n",
      "train loss:0.17953458216734827\n",
      "train loss:0.173851334807282\n",
      "train loss:0.2276019118805289\n",
      "train loss:0.16757220446825577\n",
      "train loss:0.3209246297175363\n",
      "train loss:0.16659367548158455\n",
      "train loss:0.20305780751537095\n",
      "train loss:0.09107376615954949\n",
      "train loss:0.12838884516036547\n",
      "train loss:0.14280136629321669\n",
      "train loss:0.2863751551832875\n",
      "train loss:0.16836507787847377\n",
      "train loss:0.0857893617331731\n",
      "train loss:0.1287813109735042\n",
      "train loss:0.15273310706922658\n",
      "train loss:0.1631295870662024\n",
      "train loss:0.1313559288148242\n",
      "train loss:0.15042324194649537\n",
      "train loss:0.18663135877135076\n",
      "train loss:0.1363106482755954\n",
      "train loss:0.11563289440770724\n",
      "train loss:0.07303561825279183\n",
      "train loss:0.12009925600336596\n",
      "train loss:0.218596983227353\n",
      "train loss:0.27886966344897723\n",
      "train loss:0.19356148513341728\n",
      "train loss:0.20963130417228001\n",
      "train loss:0.21761861835006374\n",
      "train loss:0.19383454296455568\n",
      "train loss:0.3345495821586226\n",
      "train loss:0.07715826523345948\n",
      "train loss:0.08632621623454399\n",
      "train loss:0.25786129459462914\n",
      "train loss:0.12136841223565524\n",
      "train loss:0.12857316580402717\n",
      "train loss:0.19278732896942688\n",
      "train loss:0.22816494456417774\n",
      "train loss:0.147851439372432\n",
      "train loss:0.2278756085572949\n",
      "train loss:0.12616956566701534\n",
      "train loss:0.2091421290397949\n",
      "train loss:0.1013363923125241\n",
      "train loss:0.18689565628465604\n",
      "train loss:0.2258892256667093\n",
      "train loss:0.17878293699472575\n",
      "train loss:0.21179050975603317\n",
      "train loss:0.21451609928599902\n",
      "train loss:0.2584440585822509\n",
      "train loss:0.14778143951722053\n",
      "train loss:0.19692921753312662\n",
      "train loss:0.22580726182445385\n",
      "train loss:0.06836442186044002\n",
      "train loss:0.117446676176916\n",
      "train loss:0.11351179523667651\n",
      "train loss:0.1960414332263284\n",
      "train loss:0.3016204224300533\n",
      "train loss:0.19833517839969622\n",
      "train loss:0.19243174774514188\n",
      "train loss:0.11275318262724471\n",
      "train loss:0.15259026242090773\n",
      "train loss:0.07773879778323807\n",
      "train loss:0.09697967783735416\n",
      "train loss:0.1484229016205451\n",
      "train loss:0.11090926119037904\n",
      "train loss:0.16476049267223478\n",
      "train loss:0.09887256961500962\n",
      "train loss:0.22185430695932648\n",
      "train loss:0.24031028951638567\n",
      "train loss:0.10724938361501551\n",
      "train loss:0.2791142706832851\n",
      "train loss:0.14251795373420065\n",
      "train loss:0.1180259597182251\n",
      "train loss:0.2454253649385086\n",
      "train loss:0.20180900234809354\n",
      "train loss:0.13919946066032785\n",
      "train loss:0.1638637973167868\n",
      "train loss:0.1369380525654449\n",
      "train loss:0.08224632932346018\n",
      "train loss:0.13469683872300606\n",
      "train loss:0.062289185116099786\n",
      "train loss:0.1950517565988225\n",
      "train loss:0.06401974802328439\n",
      "train loss:0.25075138043087664\n",
      "train loss:0.15043826680105993\n",
      "train loss:0.09250613571296071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1328199228064972\n",
      "train loss:0.18770858225093423\n",
      "train loss:0.24277698156881264\n",
      "train loss:0.12744395270957437\n",
      "train loss:0.11390826582499508\n",
      "train loss:0.1931318434981812\n",
      "train loss:0.37130062424737126\n",
      "train loss:0.318126999170048\n",
      "train loss:0.12903107709498746\n",
      "train loss:0.12155537367949468\n",
      "train loss:0.2664048869115375\n",
      "train loss:0.24990732651532377\n",
      "train loss:0.22030671357700757\n",
      "train loss:0.1995899164128243\n",
      "train loss:0.1277941372440951\n",
      "train loss:0.10466004891581752\n",
      "train loss:0.10493377165506512\n",
      "train loss:0.14985112031932366\n",
      "train loss:0.10358811708071648\n",
      "train loss:0.12278379220385557\n",
      "train loss:0.051781723052246625\n",
      "train loss:0.20191317952963966\n",
      "train loss:0.048268337264240485\n",
      "train loss:0.07083009644761891\n",
      "train loss:0.1717853592826908\n",
      "train loss:0.14915369237797332\n",
      "train loss:0.0818617371262522\n",
      "train loss:0.1956503858285056\n",
      "train loss:0.12181274242252252\n",
      "train loss:0.07665815330416872\n",
      "train loss:0.12943226865414573\n",
      "train loss:0.07654085832762844\n",
      "train loss:0.1437592115950518\n",
      "train loss:0.20608390605928778\n",
      "train loss:0.18729908098212322\n",
      "train loss:0.09112054187153104\n",
      "train loss:0.12678171361511661\n",
      "train loss:0.16879073277259996\n",
      "train loss:0.14985501212595836\n",
      "train loss:0.2491727256903908\n",
      "train loss:0.2151391143435808\n",
      "train loss:0.179937576822188\n",
      "train loss:0.20499707998412087\n",
      "train loss:0.1178779505561691\n",
      "train loss:0.06795031792289817\n",
      "train loss:0.24176638210982176\n",
      "train loss:0.11720791623994156\n",
      "train loss:0.09445645014562308\n",
      "train loss:0.16541770147749982\n",
      "train loss:0.14205264564228368\n",
      "train loss:0.14820661590912745\n",
      "train loss:0.07341099330755488\n",
      "train loss:0.13975646823076038\n",
      "train loss:0.1775472634932652\n",
      "train loss:0.1768666773844843\n",
      "train loss:0.0948363675643748\n",
      "train loss:0.14239134050788194\n",
      "train loss:0.13903904594129313\n",
      "train loss:0.11839877802717037\n",
      "train loss:0.15249653425612986\n",
      "train loss:0.20000657092113483\n",
      "train loss:0.08472229936208446\n",
      "train loss:0.13984181035153231\n",
      "train loss:0.1338247061214807\n",
      "train loss:0.18405656317082417\n",
      "train loss:0.1817179668863025\n",
      "train loss:0.06544806335258763\n",
      "train loss:0.19976527337959626\n",
      "train loss:0.12470967353645455\n",
      "train loss:0.08227122451894454\n",
      "train loss:0.15696120681744571\n",
      "train loss:0.07944532748798368\n",
      "train loss:0.050399981538038006\n",
      "train loss:0.08159566157391097\n",
      "train loss:0.15574796460176346\n",
      "train loss:0.07409087186862796\n",
      "train loss:0.08977895232228404\n",
      "train loss:0.10326135629976817\n",
      "train loss:0.2232330013749323\n",
      "train loss:0.06374854299852202\n",
      "train loss:0.2255398955864582\n",
      "train loss:0.08628622244050017\n",
      "train loss:0.06182605305772892\n",
      "train loss:0.09801676473771376\n",
      "train loss:0.2832186062896111\n",
      "train loss:0.07089537500893142\n",
      "train loss:0.060843927771404356\n",
      "train loss:0.10890383532160047\n",
      "train loss:0.10016749106767454\n",
      "train loss:0.09875308930866958\n",
      "train loss:0.13277145569738755\n",
      "train loss:0.06810981253315315\n",
      "train loss:0.11604648054852733\n",
      "train loss:0.16742590945976288\n",
      "train loss:0.17075820310147385\n",
      "train loss:0.12199782445929695\n",
      "train loss:0.12564412630577823\n",
      "train loss:0.1531429584384434\n",
      "train loss:0.038235555079237434\n",
      "train loss:0.14260556951911454\n",
      "train loss:0.26311982418335417\n",
      "train loss:0.14012109596633335\n",
      "train loss:0.13202178930735045\n",
      "train loss:0.14748564464465064\n",
      "train loss:0.10896401575258827\n",
      "train loss:0.12574389394476768\n",
      "train loss:0.11725346057163302\n",
      "train loss:0.15543519757016067\n",
      "train loss:0.12086763507520681\n",
      "train loss:0.11274425026036727\n",
      "train loss:0.30090186354301024\n",
      "train loss:0.2053391470802935\n",
      "train loss:0.04370902435027231\n",
      "train loss:0.10702648139464907\n",
      "train loss:0.1041315688281895\n",
      "train loss:0.1407759339001828\n",
      "train loss:0.11516358739292824\n",
      "train loss:0.10406328399201575\n",
      "train loss:0.06354086030808542\n",
      "train loss:0.17695818340097083\n",
      "train loss:0.3052003310079684\n",
      "train loss:0.05160095038978293\n",
      "train loss:0.12838651643600707\n",
      "train loss:0.1040606817956585\n",
      "train loss:0.19243187816783083\n",
      "train loss:0.06819038908224725\n",
      "train loss:0.17145828247196143\n",
      "train loss:0.17692989264014156\n",
      "train loss:0.11562432848493699\n",
      "train loss:0.17429402232265737\n",
      "train loss:0.1558244232553474\n",
      "train loss:0.1644018283478561\n",
      "train loss:0.206309857183737\n",
      "train loss:0.1140022688369608\n",
      "train loss:0.10826701645059139\n",
      "train loss:0.1651146838344912\n",
      "train loss:0.1596321743599528\n",
      "train loss:0.08678169366935352\n",
      "train loss:0.1461897279123179\n",
      "train loss:0.1113606962078912\n",
      "train loss:0.08959068646559677\n",
      "train loss:0.17302397763086458\n",
      "train loss:0.11065173131444603\n",
      "train loss:0.19881751699226793\n",
      "train loss:0.12176077170937667\n",
      "train loss:0.06842175216930226\n",
      "train loss:0.054369584137499795\n",
      "train loss:0.1015136170093432\n",
      "train loss:0.1511522939842817\n",
      "train loss:0.10743715736878257\n",
      "train loss:0.11709575046159815\n",
      "train loss:0.0780157407435357\n",
      "train loss:0.11360243212875883\n",
      "train loss:0.15966917372738118\n",
      "train loss:0.08584138986065501\n",
      "train loss:0.19393090724422568\n",
      "train loss:0.08298040670762293\n",
      "train loss:0.12109061087538991\n",
      "train loss:0.3627062589815678\n",
      "train loss:0.08397686997435169\n",
      "train loss:0.12687659978264187\n",
      "train loss:0.09529224990668621\n",
      "train loss:0.0831818025194627\n",
      "train loss:0.08352376187871606\n",
      "train loss:0.20897982092175307\n",
      "train loss:0.09318242525512081\n",
      "train loss:0.3921870723990492\n",
      "train loss:0.11808403168200582\n",
      "train loss:0.11474801152859833\n",
      "train loss:0.07945697467865886\n",
      "train loss:0.19260122739393634\n",
      "train loss:0.16995296526452158\n",
      "train loss:0.07179506695701185\n",
      "train loss:0.15777643371659297\n",
      "train loss:0.06174373390153229\n",
      "train loss:0.1006920713791502\n",
      "train loss:0.19080173793700086\n",
      "train loss:0.16780475713354373\n",
      "train loss:0.07544590813229413\n",
      "train loss:0.12312189860938817\n",
      "train loss:0.16386723989908009\n",
      "train loss:0.13750878102040842\n",
      "train loss:0.17582468889065364\n",
      "train loss:0.11127781736897693\n",
      "train loss:0.098492587728701\n",
      "train loss:0.06656085271509443\n",
      "train loss:0.3477983693922767\n",
      "train loss:0.1638243535506281\n",
      "train loss:0.10707793188061553\n",
      "train loss:0.10796412065952538\n",
      "train loss:0.09089901681521421\n",
      "train loss:0.1080822422518579\n",
      "train loss:0.1713430595045833\n",
      "train loss:0.060060533298548144\n",
      "train loss:0.09242920860314081\n",
      "train loss:0.08375358194420443\n",
      "train loss:0.10741538576189277\n",
      "train loss:0.033880443531013646\n",
      "train loss:0.18556909198636326\n",
      "train loss:0.2346327936472974\n",
      "train loss:0.09658139396619743\n",
      "train loss:0.10667476398189672\n",
      "train loss:0.22364701223482203\n",
      "train loss:0.208103547890851\n",
      "train loss:0.09795856200456582\n",
      "train loss:0.1422399293870501\n",
      "train loss:0.10309258175943105\n",
      "train loss:0.06628911950904698\n",
      "train loss:0.13965637333571748\n",
      "train loss:0.08092997609604184\n",
      "train loss:0.0991305164913123\n",
      "train loss:0.13561052805977203\n",
      "train loss:0.15359696989427812\n",
      "train loss:0.1950300163428168\n",
      "train loss:0.08930115646019127\n",
      "train loss:0.0824976595133054\n",
      "train loss:0.055232593026491764\n",
      "train loss:0.10818260972154796\n",
      "train loss:0.1476715653468851\n",
      "train loss:0.11601424169603464\n",
      "train loss:0.10592556952984196\n",
      "train loss:0.08326775193463157\n",
      "train loss:0.09627363828411672\n",
      "train loss:0.09689940739364916\n",
      "train loss:0.10528336460980783\n",
      "train loss:0.19364740085141785\n",
      "train loss:0.14605514939504652\n",
      "train loss:0.1621675750195293\n",
      "train loss:0.05648451718713052\n",
      "train loss:0.08463114415519266\n",
      "train loss:0.18188955221424916\n",
      "train loss:0.1438063203748086\n",
      "train loss:0.08028261282011712\n",
      "train loss:0.18602809996000144\n",
      "train loss:0.17495971948826378\n",
      "train loss:0.09507465187845403\n",
      "train loss:0.09816356896167472\n",
      "train loss:0.09582842360865271\n",
      "train loss:0.07810555058269993\n",
      "train loss:0.04601771815831917\n",
      "train loss:0.15004979256107054\n",
      "train loss:0.10179833173637064\n",
      "train loss:0.1707386704942206\n",
      "train loss:0.17493234393704174\n",
      "train loss:0.19132131364280158\n",
      "train loss:0.1346858101524977\n",
      "train loss:0.426746356169592\n",
      "train loss:0.10620395518364413\n",
      "train loss:0.19738310610262175\n",
      "train loss:0.1270660502990994\n",
      "train loss:0.10648922399515287\n",
      "train loss:0.08374311256623775\n",
      "train loss:0.16007140770463527\n",
      "train loss:0.15584619792927723\n",
      "train loss:0.07067855183048062\n",
      "train loss:0.1067158727402691\n",
      "train loss:0.13317801515604338\n",
      "train loss:0.12938541092858352\n",
      "train loss:0.12207105535531439\n",
      "train loss:0.05981561954431186\n",
      "train loss:0.14800702495321022\n",
      "train loss:0.11382946259837844\n",
      "train loss:0.12435749432660756\n",
      "train loss:0.23004504598748393\n",
      "train loss:0.07940960942635701\n",
      "train loss:0.041751717536402354\n",
      "train loss:0.21733531426814318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10064604414287005\n",
      "train loss:0.06542348250559443\n",
      "train loss:0.06446056024261645\n",
      "train loss:0.20017573426963675\n",
      "train loss:0.08352150731652307\n",
      "train loss:0.1579945189664467\n",
      "train loss:0.06676200343212005\n",
      "train loss:0.09986800962719773\n",
      "train loss:0.11205284206546323\n",
      "train loss:0.11863965033189373\n",
      "train loss:0.13496954537447506\n",
      "train loss:0.09407964107628661\n",
      "train loss:0.08003342977850726\n",
      "train loss:0.14424639999502697\n",
      "train loss:0.10901893934182887\n",
      "train loss:0.09118281570623844\n",
      "train loss:0.12272499264130105\n",
      "train loss:0.0784814571833382\n",
      "train loss:0.13778469350872774\n",
      "train loss:0.07370806054509871\n",
      "train loss:0.06305088161169861\n",
      "train loss:0.14638113017143578\n",
      "train loss:0.1606853699215219\n",
      "train loss:0.06056895976569255\n",
      "train loss:0.23420656547564234\n",
      "train loss:0.054191483030591764\n",
      "train loss:0.08050759096869027\n",
      "train loss:0.12964943500131917\n",
      "train loss:0.17295842860329386\n",
      "train loss:0.20511554945131258\n",
      "train loss:0.09005074742849407\n",
      "train loss:0.1452666813816324\n",
      "train loss:0.10295013019464483\n",
      "train loss:0.05058093180290402\n",
      "train loss:0.12053179959180615\n",
      "train loss:0.1473688398193742\n",
      "train loss:0.15058701839329777\n",
      "train loss:0.1638439436842139\n",
      "train loss:0.20901104600694598\n",
      "train loss:0.060530828153064695\n",
      "train loss:0.17244819156455904\n",
      "train loss:0.18564260942043329\n",
      "train loss:0.20039060974428288\n",
      "train loss:0.04928409147745048\n",
      "train loss:0.1457103997993612\n",
      "train loss:0.08944242334808072\n",
      "train loss:0.05982420978498884\n",
      "train loss:0.04099729909758842\n",
      "train loss:0.10153435769102243\n",
      "train loss:0.04574878534602633\n",
      "train loss:0.12361612923985668\n",
      "train loss:0.09822786243009625\n",
      "train loss:0.11905785798901937\n",
      "train loss:0.26212650917305846\n",
      "train loss:0.08633665389590427\n",
      "train loss:0.10527841553109596\n",
      "train loss:0.07468467323512383\n",
      "train loss:0.07790982591838624\n",
      "train loss:0.06306490212779389\n",
      "train loss:0.06498863499650882\n",
      "train loss:0.17322983142471146\n",
      "train loss:0.1447133768290789\n",
      "train loss:0.15809550027886365\n",
      "train loss:0.1530665971090551\n",
      "train loss:0.06020646897746218\n",
      "train loss:0.059930266432898394\n",
      "train loss:0.12058550632638325\n",
      "train loss:0.2625705817148519\n",
      "train loss:0.07949493251112864\n",
      "train loss:0.09793995165397978\n",
      "train loss:0.03318178501032564\n",
      "train loss:0.18957915221951763\n",
      "train loss:0.04717506486420885\n",
      "train loss:0.07513586838410348\n",
      "train loss:0.15206013562428405\n",
      "train loss:0.1221308460191803\n",
      "train loss:0.0965908941408551\n",
      "train loss:0.22334905079156342\n",
      "train loss:0.05016821450579648\n",
      "train loss:0.2084100681373216\n",
      "train loss:0.03605202649004443\n",
      "train loss:0.04138267010947987\n",
      "train loss:0.07565327066554807\n",
      "train loss:0.13693863833853734\n",
      "train loss:0.16153792433408787\n",
      "train loss:0.13184453078005645\n",
      "train loss:0.15279102671843575\n",
      "train loss:0.06327562964716367\n",
      "train loss:0.13775795838536362\n",
      "train loss:0.10459044846463841\n",
      "train loss:0.09153158915233701\n",
      "train loss:0.04887162334363279\n",
      "train loss:0.19541019817807212\n",
      "train loss:0.12811751772570626\n",
      "train loss:0.14890192632412327\n",
      "train loss:0.17264550137278295\n",
      "train loss:0.07766378538878149\n",
      "train loss:0.0673713773341786\n",
      "train loss:0.14216301060910447\n",
      "train loss:0.1914463574067485\n",
      "train loss:0.2775613795173676\n",
      "train loss:0.07034637433965557\n",
      "train loss:0.14074692548153225\n",
      "train loss:0.15983535407804564\n",
      "train loss:0.22789047027486006\n",
      "train loss:0.2312152835195894\n",
      "train loss:0.06813420537407568\n",
      "train loss:0.11254058693639772\n",
      "train loss:0.108542309293918\n",
      "train loss:0.13351173968221583\n",
      "train loss:0.12759206354089123\n",
      "train loss:0.06062550175853522\n",
      "train loss:0.0782421320529953\n",
      "train loss:0.13568720651468877\n",
      "train loss:0.1480765218542474\n",
      "train loss:0.1439448977020344\n",
      "train loss:0.15443207650600982\n",
      "train loss:0.05407195369548767\n",
      "train loss:0.16894119436382432\n",
      "train loss:0.1598287199651436\n",
      "train loss:0.1541455616418962\n",
      "train loss:0.14291603064021455\n",
      "train loss:0.09503887572479805\n",
      "train loss:0.14169520220113968\n",
      "train loss:0.07514075855915384\n",
      "train loss:0.15627141517136586\n",
      "train loss:0.13089199659362344\n",
      "train loss:0.10180522757669674\n",
      "train loss:0.0502342429472503\n",
      "train loss:0.10125265263561445\n",
      "=== epoch:3, train acc:0.966, test acc:0.967 ===\n",
      "train loss:0.12888301730012172\n",
      "train loss:0.09180809989040459\n",
      "train loss:0.07305354520826496\n",
      "train loss:0.08538751696959868\n",
      "train loss:0.11833784207380621\n",
      "train loss:0.07630143631883328\n",
      "train loss:0.0755328407833448\n",
      "train loss:0.12434226175397953\n",
      "train loss:0.0926028226719739\n",
      "train loss:0.11436898573858299\n",
      "train loss:0.06819787154489293\n",
      "train loss:0.11588558840797827\n",
      "train loss:0.18140174412218987\n",
      "train loss:0.09949853803831693\n",
      "train loss:0.08578313328807376\n",
      "train loss:0.04535789107327752\n",
      "train loss:0.12526796741934063\n",
      "train loss:0.02748295837891301\n",
      "train loss:0.04971043057933566\n",
      "train loss:0.14774961732159722\n",
      "train loss:0.1861012166702892\n",
      "train loss:0.10287973409312447\n",
      "train loss:0.06361083676316348\n",
      "train loss:0.15323730199303845\n",
      "train loss:0.1502256391681003\n",
      "train loss:0.11552517172772235\n",
      "train loss:0.05733567244723207\n",
      "train loss:0.15523794049982523\n",
      "train loss:0.04901753492371199\n",
      "train loss:0.106598629512913\n",
      "train loss:0.08187643403304799\n",
      "train loss:0.12460153142908867\n",
      "train loss:0.14416773437423044\n",
      "train loss:0.09602658381821536\n",
      "train loss:0.12428689048805325\n",
      "train loss:0.12899720514509652\n",
      "train loss:0.10070727606966667\n",
      "train loss:0.07257865091763571\n",
      "train loss:0.1904377645795162\n",
      "train loss:0.07047682710578484\n",
      "train loss:0.0746494543803684\n",
      "train loss:0.1297510016244796\n",
      "train loss:0.16790332760787133\n",
      "train loss:0.04437491753944239\n",
      "train loss:0.04722642569124698\n",
      "train loss:0.12285706687390084\n",
      "train loss:0.061016604937455865\n",
      "train loss:0.09511350153690305\n",
      "train loss:0.034579354565038\n",
      "train loss:0.05740384380777045\n",
      "train loss:0.10640465934999827\n",
      "train loss:0.04068219539994671\n",
      "train loss:0.07107430970845088\n",
      "train loss:0.12928291620641857\n",
      "train loss:0.06451872730453379\n",
      "train loss:0.051888393726741235\n",
      "train loss:0.0906509930594615\n",
      "train loss:0.04524700333606591\n",
      "train loss:0.11267308248128824\n",
      "train loss:0.06526492428922386\n",
      "train loss:0.11051526091809448\n",
      "train loss:0.13542897311445107\n",
      "train loss:0.05107391429506497\n",
      "train loss:0.07782258176357754\n",
      "train loss:0.11579432598080448\n",
      "train loss:0.08601233073208998\n",
      "train loss:0.04227371722475719\n",
      "train loss:0.1144915132877977\n",
      "train loss:0.0778375216100509\n",
      "train loss:0.15133233342037333\n",
      "train loss:0.07831132978556783\n",
      "train loss:0.08956357817673025\n",
      "train loss:0.041032108847009224\n",
      "train loss:0.14211628715492863\n",
      "train loss:0.10377053871512368\n",
      "train loss:0.06518717665078168\n",
      "train loss:0.04989145584945608\n",
      "train loss:0.18840732417701048\n",
      "train loss:0.1362522481757241\n",
      "train loss:0.06892835320658391\n",
      "train loss:0.032934294998953104\n",
      "train loss:0.0869533418304555\n",
      "train loss:0.12136018039908716\n",
      "train loss:0.028928196966849163\n",
      "train loss:0.0614240856232146\n",
      "train loss:0.05976532257496947\n",
      "train loss:0.142356022300395\n",
      "train loss:0.09472486327071306\n",
      "train loss:0.06458241217557865\n",
      "train loss:0.13840918790663903\n",
      "train loss:0.041610216323359414\n",
      "train loss:0.07465241914026322\n",
      "train loss:0.19078879009451505\n",
      "train loss:0.17768504608839242\n",
      "train loss:0.05855493533684277\n",
      "train loss:0.07354154873497198\n",
      "train loss:0.06581352570306116\n",
      "train loss:0.08907860172865592\n",
      "train loss:0.03920287926278383\n",
      "train loss:0.059755325389994667\n",
      "train loss:0.0822780923398366\n",
      "train loss:0.17074801970871525\n",
      "train loss:0.05104966093517385\n",
      "train loss:0.13994253185945832\n",
      "train loss:0.0509961276526281\n",
      "train loss:0.1728427774155241\n",
      "train loss:0.12629172187868412\n",
      "train loss:0.16145803101028025\n",
      "train loss:0.15895263085761585\n",
      "train loss:0.068779267450022\n",
      "train loss:0.11964855791460317\n",
      "train loss:0.046004309522585406\n",
      "train loss:0.08485738784395493\n",
      "train loss:0.07662412943244944\n",
      "train loss:0.09061314197866706\n",
      "train loss:0.07001932188438993\n",
      "train loss:0.16331599143539216\n",
      "train loss:0.15242276581305914\n",
      "train loss:0.13845642094650112\n",
      "train loss:0.09772696424457987\n",
      "train loss:0.036064232129968406\n",
      "train loss:0.09032193849941379\n",
      "train loss:0.034909200912113164\n",
      "train loss:0.06241696954301936\n",
      "train loss:0.0742469105106233\n",
      "train loss:0.21421093810353714\n",
      "train loss:0.0314629523490317\n",
      "train loss:0.12208939121674922\n",
      "train loss:0.15100087711667623\n",
      "train loss:0.0776529044465871\n",
      "train loss:0.09961656669600943\n",
      "train loss:0.13165104826684096\n",
      "train loss:0.20230569849521918\n",
      "train loss:0.09933841613886372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08617866949866076\n",
      "train loss:0.0915696296482558\n",
      "train loss:0.03126975565277203\n",
      "train loss:0.04896951516135873\n",
      "train loss:0.187355869634679\n",
      "train loss:0.0702549540047312\n",
      "train loss:0.05100674350091702\n",
      "train loss:0.11825750977456793\n",
      "train loss:0.09939324677815764\n",
      "train loss:0.10444040864722041\n",
      "train loss:0.09841569811164655\n",
      "train loss:0.134681364149491\n",
      "train loss:0.11620930122530806\n",
      "train loss:0.05123354712654828\n",
      "train loss:0.11173030499899857\n",
      "train loss:0.05739019300451453\n",
      "train loss:0.0914714048902915\n",
      "train loss:0.09546363988258082\n",
      "train loss:0.10022033320824825\n",
      "train loss:0.16075238287412108\n",
      "train loss:0.04361530483835905\n",
      "train loss:0.047401436406203735\n",
      "train loss:0.06661762525449454\n",
      "train loss:0.027675712456078673\n",
      "train loss:0.0997015253817107\n",
      "train loss:0.06028492509863784\n",
      "train loss:0.2660813610613526\n",
      "train loss:0.14868026311050608\n",
      "train loss:0.039129505428712595\n",
      "train loss:0.11379448387261505\n",
      "train loss:0.06915539911228862\n",
      "train loss:0.1844628496612528\n",
      "train loss:0.0770521433402545\n",
      "train loss:0.04770810742501056\n",
      "train loss:0.08726888974342936\n",
      "train loss:0.09493906600296682\n",
      "train loss:0.04553196981009155\n",
      "train loss:0.10405127121905122\n",
      "train loss:0.04490801707828711\n",
      "train loss:0.14246313881764963\n",
      "train loss:0.1730362737703758\n",
      "train loss:0.03202497909807988\n",
      "train loss:0.09793934883727604\n",
      "train loss:0.1641285744705055\n",
      "train loss:0.09506880484228582\n",
      "train loss:0.054785578448133254\n",
      "train loss:0.0845659691202623\n",
      "train loss:0.12958866524847376\n",
      "train loss:0.05505666189875871\n",
      "train loss:0.07791041275845853\n",
      "train loss:0.16323287584455912\n",
      "train loss:0.14398789510303703\n",
      "train loss:0.068522110845576\n",
      "train loss:0.17507341800699475\n",
      "train loss:0.12208414644559074\n",
      "train loss:0.10478538792714798\n",
      "train loss:0.09438418946226813\n",
      "train loss:0.10319868235466469\n",
      "train loss:0.05169372465626964\n",
      "train loss:0.14063126800545134\n",
      "train loss:0.13806780234733973\n",
      "train loss:0.07161457422470568\n",
      "train loss:0.08333848315550732\n",
      "train loss:0.10629083086399653\n",
      "train loss:0.03523608010332769\n",
      "train loss:0.07739643795484506\n",
      "train loss:0.05073479283692943\n",
      "train loss:0.10473352613272617\n",
      "train loss:0.031391139428968456\n",
      "train loss:0.05852452752047709\n",
      "train loss:0.0802175383659625\n",
      "train loss:0.09539595543520893\n",
      "train loss:0.10855386636731028\n",
      "train loss:0.05155539500594917\n",
      "train loss:0.07617456660387849\n",
      "train loss:0.05135334225875807\n",
      "train loss:0.07242861543061294\n",
      "train loss:0.1099941499930464\n",
      "train loss:0.1163184197499675\n",
      "train loss:0.13712958087602073\n",
      "train loss:0.08096885343525584\n",
      "train loss:0.05120595518335286\n",
      "train loss:0.10040370304762991\n",
      "train loss:0.19057176886832639\n",
      "train loss:0.09499900735067505\n",
      "train loss:0.050638754358981866\n",
      "train loss:0.07062144894117792\n",
      "train loss:0.07056074282733876\n",
      "train loss:0.021186168318437493\n",
      "train loss:0.06564375038602016\n",
      "train loss:0.02399736020372577\n",
      "train loss:0.09049029838936004\n",
      "train loss:0.12325524759274412\n",
      "train loss:0.08548763852573098\n",
      "train loss:0.09776713113789169\n",
      "train loss:0.20465676933502863\n",
      "train loss:0.043294530515153154\n",
      "train loss:0.07274746353186887\n",
      "train loss:0.0956650741412574\n",
      "train loss:0.09286584892514181\n",
      "train loss:0.07427353518027306\n",
      "train loss:0.11213577719214075\n",
      "train loss:0.03436576358062743\n",
      "train loss:0.061419628712714225\n",
      "train loss:0.0515779083981826\n",
      "train loss:0.06251168781781095\n",
      "train loss:0.05632377562790378\n",
      "train loss:0.054873272220696906\n",
      "train loss:0.13865902739669755\n",
      "train loss:0.1645312617639054\n",
      "train loss:0.10747766499689877\n",
      "train loss:0.08712225207621457\n",
      "train loss:0.08909081142491965\n",
      "train loss:0.08228740529704842\n",
      "train loss:0.06508886401178075\n",
      "train loss:0.13538940332791138\n",
      "train loss:0.047018423521849956\n",
      "train loss:0.03958279961015069\n",
      "train loss:0.08247072326752387\n",
      "train loss:0.09388501093893659\n",
      "train loss:0.11975687923802157\n",
      "train loss:0.12935312472784427\n",
      "train loss:0.0939993431964707\n",
      "train loss:0.1548946761525469\n",
      "train loss:0.0930444977494898\n",
      "train loss:0.12058893155520767\n",
      "train loss:0.10088460729431169\n",
      "train loss:0.06248290482792753\n",
      "train loss:0.0324358935082878\n",
      "train loss:0.07403008557577115\n",
      "train loss:0.17872832924542992\n",
      "train loss:0.05809999315117944\n",
      "train loss:0.17001221168047514\n",
      "train loss:0.07122703908036042\n",
      "train loss:0.16365479050691054\n",
      "train loss:0.03475982106440231\n",
      "train loss:0.04073105164230015\n",
      "train loss:0.07828023273946713\n",
      "train loss:0.04703904360842642\n",
      "train loss:0.08854584573896387\n",
      "train loss:0.13862603324066805\n",
      "train loss:0.10192025595857973\n",
      "train loss:0.06570402989706257\n",
      "train loss:0.14335313980780418\n",
      "train loss:0.061683597798511555\n",
      "train loss:0.053031486897873126\n",
      "train loss:0.09738168604876199\n",
      "train loss:0.056259623509664215\n",
      "train loss:0.09754427400896079\n",
      "train loss:0.10043234815820487\n",
      "train loss:0.03423470816601939\n",
      "train loss:0.12590106326830608\n",
      "train loss:0.07263802437713167\n",
      "train loss:0.11299810287497661\n",
      "train loss:0.06488769874334474\n",
      "train loss:0.21950186041393535\n",
      "train loss:0.0690821667648388\n",
      "train loss:0.09505270320464967\n",
      "train loss:0.13327527006444695\n",
      "train loss:0.12634731010798395\n",
      "train loss:0.06465915569682337\n",
      "train loss:0.1402070326863024\n",
      "train loss:0.07264823118428639\n",
      "train loss:0.08124487332770064\n",
      "train loss:0.08259199211921434\n",
      "train loss:0.09545979814943129\n",
      "train loss:0.0524888269883413\n",
      "train loss:0.05625187413981408\n",
      "train loss:0.0957051824278747\n",
      "train loss:0.0912448400166364\n",
      "train loss:0.06179587699938751\n",
      "train loss:0.11579868474665542\n",
      "train loss:0.05039199485509329\n",
      "train loss:0.05617979412945921\n",
      "train loss:0.07498841972534727\n",
      "train loss:0.11816211675549645\n",
      "train loss:0.05937841124202345\n",
      "train loss:0.12205200849595432\n",
      "train loss:0.031094281115797408\n",
      "train loss:0.08829618784351462\n",
      "train loss:0.06742367758613754\n",
      "train loss:0.04697689702079418\n",
      "train loss:0.06185374350972164\n",
      "train loss:0.21475375032697927\n",
      "train loss:0.18417912912247103\n",
      "train loss:0.03176086965202669\n",
      "train loss:0.09575072115983582\n",
      "train loss:0.1205874949423034\n",
      "train loss:0.04555046365319794\n",
      "train loss:0.15122766198920465\n",
      "train loss:0.2262704411584423\n",
      "train loss:0.048085279189449215\n",
      "train loss:0.08281268601908558\n",
      "train loss:0.15824538283470463\n",
      "train loss:0.1553724008709295\n",
      "train loss:0.09079653047261306\n",
      "train loss:0.17673300937723982\n",
      "train loss:0.11506608392208463\n",
      "train loss:0.13382057539749603\n",
      "train loss:0.11571012348526358\n",
      "train loss:0.10093364895835785\n",
      "train loss:0.13909821032341194\n",
      "train loss:0.13562691272504412\n",
      "train loss:0.10615683405629789\n",
      "train loss:0.03883605871687385\n",
      "train loss:0.07591051695018114\n",
      "train loss:0.08643462547707043\n",
      "train loss:0.05342571428135755\n",
      "train loss:0.09839639966653663\n",
      "train loss:0.12110023562053478\n",
      "train loss:0.054841082829958525\n",
      "train loss:0.09191513702194934\n",
      "train loss:0.14494088518169268\n",
      "train loss:0.027270025966935178\n",
      "train loss:0.15331676869020744\n",
      "train loss:0.14903947382463653\n",
      "train loss:0.09820032231205607\n",
      "train loss:0.10960827548369492\n",
      "train loss:0.08600405838645747\n",
      "train loss:0.0609902110667594\n",
      "train loss:0.08760166781233546\n",
      "train loss:0.07923331059686343\n",
      "train loss:0.06280512852446556\n",
      "train loss:0.04557496278849741\n",
      "train loss:0.11852054273064906\n",
      "train loss:0.07923692884045967\n",
      "train loss:0.02196267426969155\n",
      "train loss:0.05545716697013831\n",
      "train loss:0.0819878107162861\n",
      "train loss:0.041686148171272974\n",
      "train loss:0.1374351050973975\n",
      "train loss:0.10318906382825459\n",
      "train loss:0.05397594737439161\n",
      "train loss:0.0739328917356107\n",
      "train loss:0.0998457985839259\n",
      "train loss:0.13331085574289783\n",
      "train loss:0.04333795664629321\n",
      "train loss:0.13983890229693705\n",
      "train loss:0.0444438094924718\n",
      "train loss:0.05466865702018958\n",
      "train loss:0.07253170167680056\n",
      "train loss:0.16567328768246853\n",
      "train loss:0.08177373117444564\n",
      "train loss:0.19664193316762668\n",
      "train loss:0.04438724756731482\n",
      "train loss:0.11093077110769642\n",
      "train loss:0.07809246533132733\n",
      "train loss:0.07634807895502771\n",
      "train loss:0.05395000312490364\n",
      "train loss:0.050205760479409174\n",
      "train loss:0.0277735310058619\n",
      "train loss:0.03637427949110892\n",
      "train loss:0.053204110166108425\n",
      "train loss:0.1167205931382521\n",
      "train loss:0.05518669391641518\n",
      "train loss:0.03416581700196992\n",
      "train loss:0.08237946517777658\n",
      "train loss:0.06453551168197753\n",
      "train loss:0.08647828507786105\n",
      "train loss:0.0534306213738702\n",
      "train loss:0.05732491217360952\n",
      "train loss:0.03051548997399215\n",
      "train loss:0.03592574413203952\n",
      "train loss:0.05404342616527519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.033194310649261885\n",
      "train loss:0.07595927395436627\n",
      "train loss:0.06011690424249087\n",
      "train loss:0.05860882710491039\n",
      "train loss:0.03683764918798786\n",
      "train loss:0.04173647106131883\n",
      "train loss:0.030693335486816752\n",
      "train loss:0.09867157582156823\n",
      "train loss:0.07606060560010967\n",
      "train loss:0.1674521281929265\n",
      "train loss:0.12783422404703176\n",
      "train loss:0.09549951443557944\n",
      "train loss:0.052509926870741054\n",
      "train loss:0.10985425884570722\n",
      "train loss:0.08837358100605025\n",
      "train loss:0.0615775816090224\n",
      "train loss:0.19180153874697742\n",
      "train loss:0.1706718821971785\n",
      "train loss:0.019976553148198378\n",
      "train loss:0.07772433746927276\n",
      "train loss:0.07461488278120945\n",
      "train loss:0.039222221655842285\n",
      "train loss:0.16611481088297203\n",
      "train loss:0.032446969227157195\n",
      "train loss:0.019841576160586284\n",
      "train loss:0.049335359242055926\n",
      "train loss:0.14349784527956078\n",
      "train loss:0.10235832423016313\n",
      "train loss:0.12859945901238082\n",
      "train loss:0.12506180720301555\n",
      "train loss:0.03423080387173109\n",
      "train loss:0.079123699388044\n",
      "train loss:0.20460001697110475\n",
      "train loss:0.08419499643141372\n",
      "train loss:0.08337139355249856\n",
      "train loss:0.02250409615364238\n",
      "train loss:0.021349346286681555\n",
      "train loss:0.10405230180838763\n",
      "train loss:0.1067521116157982\n",
      "train loss:0.0951819653288771\n",
      "train loss:0.09958277594261335\n",
      "train loss:0.0675485956763524\n",
      "train loss:0.07873271976964209\n",
      "train loss:0.0685512925546404\n",
      "train loss:0.08740377588192154\n",
      "train loss:0.05962266911438416\n",
      "train loss:0.09547744558868491\n",
      "train loss:0.08829026616594443\n",
      "train loss:0.05604113546342146\n",
      "train loss:0.10362694258463684\n",
      "train loss:0.15274037824669176\n",
      "train loss:0.16403747863782678\n",
      "train loss:0.02786184551167505\n",
      "train loss:0.05635857434750736\n",
      "train loss:0.07502435917225336\n",
      "train loss:0.059680536298270574\n",
      "train loss:0.19583628759119404\n",
      "train loss:0.07781952459421895\n",
      "train loss:0.07288141827428547\n",
      "train loss:0.13767303570871597\n",
      "train loss:0.07358319011723843\n",
      "train loss:0.0936070180532687\n",
      "train loss:0.04933901832499519\n",
      "train loss:0.0548007877891383\n",
      "train loss:0.1399208906392832\n",
      "train loss:0.09492550957922598\n",
      "train loss:0.07373895350343931\n",
      "train loss:0.08973952027635594\n",
      "train loss:0.10296983938004045\n",
      "train loss:0.08310566752123907\n",
      "train loss:0.11010563042285515\n",
      "train loss:0.04791352964158444\n",
      "train loss:0.030020791587825436\n",
      "train loss:0.0459082729277928\n",
      "train loss:0.10637573087008448\n",
      "train loss:0.08313932776082705\n",
      "train loss:0.03999792000324724\n",
      "train loss:0.08761806548603518\n",
      "train loss:0.13968074705203237\n",
      "train loss:0.07515577650751612\n",
      "train loss:0.10304131777498038\n",
      "train loss:0.07556560896971941\n",
      "train loss:0.1090729997824759\n",
      "train loss:0.0857119209152848\n",
      "train loss:0.056823335296114906\n",
      "train loss:0.022776767108097493\n",
      "train loss:0.09981144992080541\n",
      "train loss:0.033345160078680346\n",
      "train loss:0.1186853258214675\n",
      "train loss:0.11819380484922692\n",
      "train loss:0.07196151319266003\n",
      "train loss:0.03035433230663282\n",
      "train loss:0.08173674537998642\n",
      "train loss:0.10429420543021728\n",
      "train loss:0.08825197535179097\n",
      "train loss:0.054715403290735994\n",
      "train loss:0.2500900843436637\n",
      "train loss:0.051674153922186425\n",
      "train loss:0.16234752133490266\n",
      "train loss:0.03810405210012426\n",
      "train loss:0.13937031688879456\n",
      "train loss:0.09789307077446016\n",
      "train loss:0.020027234679408687\n",
      "train loss:0.10299569990123342\n",
      "train loss:0.06755514106798208\n",
      "train loss:0.06341873853706181\n",
      "train loss:0.1761807685213274\n",
      "train loss:0.12258964861946986\n",
      "train loss:0.05850510614221071\n",
      "train loss:0.042738402368244686\n",
      "train loss:0.07386275485634868\n",
      "train loss:0.07305400307257719\n",
      "train loss:0.09854610665909554\n",
      "train loss:0.03741256013593187\n",
      "train loss:0.08307762198158798\n",
      "train loss:0.09463141738734664\n",
      "train loss:0.05698390065939513\n",
      "train loss:0.12197323467475599\n",
      "train loss:0.18498995010555697\n",
      "train loss:0.04051392829891077\n",
      "train loss:0.03668353158128819\n",
      "train loss:0.0223202972761969\n",
      "train loss:0.05240740456562528\n",
      "train loss:0.032714326960451026\n",
      "train loss:0.03560342565627314\n",
      "train loss:0.03658000641900536\n",
      "train loss:0.08333026063007713\n",
      "train loss:0.03417483706260618\n",
      "train loss:0.025344016413586447\n",
      "train loss:0.11841378471431811\n",
      "train loss:0.047176970597148336\n",
      "train loss:0.06748525929370959\n",
      "train loss:0.02592744641980276\n",
      "train loss:0.07032884086959929\n",
      "train loss:0.04249418932325054\n",
      "train loss:0.02191996649982817\n",
      "train loss:0.02701991159303951\n",
      "train loss:0.11761682069722978\n",
      "train loss:0.023716474463035563\n",
      "train loss:0.0692642135450342\n",
      "train loss:0.15269469061457785\n",
      "train loss:0.08491900616475932\n",
      "train loss:0.04611829809632204\n",
      "train loss:0.1235403878554611\n",
      "train loss:0.023864926868052385\n",
      "train loss:0.04089847498162551\n",
      "train loss:0.06448892219862351\n",
      "train loss:0.2676464084778307\n",
      "train loss:0.09153519503487394\n",
      "train loss:0.033253371136620934\n",
      "train loss:0.14493383363955206\n",
      "train loss:0.02103923256118784\n",
      "train loss:0.0448980721865375\n",
      "train loss:0.1816511141422729\n",
      "train loss:0.04695824712226027\n",
      "train loss:0.14192395931621804\n",
      "train loss:0.06955126244222008\n",
      "train loss:0.10070153241992508\n",
      "train loss:0.08799018535350898\n",
      "train loss:0.028115545956319155\n",
      "train loss:0.051260052013237335\n",
      "train loss:0.04853536161812293\n",
      "train loss:0.10678173027972876\n",
      "train loss:0.08051863791772808\n",
      "train loss:0.14992730149530437\n",
      "train loss:0.08292950148096652\n",
      "train loss:0.1268768627085701\n",
      "train loss:0.07001713814425513\n",
      "train loss:0.09240512262601744\n",
      "train loss:0.022546395077512014\n",
      "train loss:0.10222223941163065\n",
      "train loss:0.08053109183961293\n",
      "train loss:0.061954572569277694\n",
      "train loss:0.04351589211085165\n",
      "train loss:0.051093807317520765\n",
      "train loss:0.056432871925364815\n",
      "train loss:0.1426284269117141\n",
      "train loss:0.040909176493808104\n",
      "train loss:0.0696543713970634\n",
      "train loss:0.09254604006638065\n",
      "train loss:0.05762468195469881\n",
      "train loss:0.041871431249998155\n",
      "train loss:0.015961047155375486\n",
      "train loss:0.08933005776598302\n",
      "train loss:0.15490949026422712\n",
      "train loss:0.10875550497124667\n",
      "train loss:0.06644305666119274\n",
      "train loss:0.09096394226047522\n",
      "train loss:0.07983122463412311\n",
      "train loss:0.1329920449717079\n",
      "train loss:0.05373140065430088\n",
      "train loss:0.026598547896354772\n",
      "train loss:0.026180288559510396\n",
      "train loss:0.10504911708378073\n",
      "train loss:0.10739168398926141\n",
      "train loss:0.05981461441417073\n",
      "train loss:0.07093476372245369\n",
      "train loss:0.07494453333458108\n",
      "train loss:0.05031941866028802\n",
      "train loss:0.1649384712359969\n",
      "train loss:0.06430506293758709\n",
      "train loss:0.05575741047547338\n",
      "=== epoch:4, train acc:0.975, test acc:0.974 ===\n",
      "train loss:0.05540528077528305\n",
      "train loss:0.06203247906220083\n",
      "train loss:0.0771107833390627\n",
      "train loss:0.0398829322470727\n",
      "train loss:0.13007210144725134\n",
      "train loss:0.10487762037563698\n",
      "train loss:0.16401052520908765\n",
      "train loss:0.054780816622967306\n",
      "train loss:0.08857155960609296\n",
      "train loss:0.0811339417005007\n",
      "train loss:0.049084433062717814\n",
      "train loss:0.09969967778132661\n",
      "train loss:0.06383069737520575\n",
      "train loss:0.06717936702951982\n",
      "train loss:0.09125348179366917\n",
      "train loss:0.05553319305298007\n",
      "train loss:0.07179891891901191\n",
      "train loss:0.07396219771122106\n",
      "train loss:0.045642333416534536\n",
      "train loss:0.04208572491468483\n",
      "train loss:0.012254430408830288\n",
      "train loss:0.021280044624311715\n",
      "train loss:0.06869723998515898\n",
      "train loss:0.11798394857580577\n",
      "train loss:0.10033567316985784\n",
      "train loss:0.09476300925130843\n",
      "train loss:0.04825452276007533\n",
      "train loss:0.04613372778505391\n",
      "train loss:0.03379738501934632\n",
      "train loss:0.08178075229097588\n",
      "train loss:0.0683419115724428\n",
      "train loss:0.061641853709912084\n",
      "train loss:0.06189336790335827\n",
      "train loss:0.03655204923984473\n",
      "train loss:0.0859038589312505\n",
      "train loss:0.09341883715098169\n",
      "train loss:0.13469833199446687\n",
      "train loss:0.06538906763031255\n",
      "train loss:0.09675730951550586\n",
      "train loss:0.023409800455653326\n",
      "train loss:0.060559981800347024\n",
      "train loss:0.026200091283133043\n",
      "train loss:0.17573674171943046\n",
      "train loss:0.05201147686408742\n",
      "train loss:0.08171413216001286\n",
      "train loss:0.0951837832676866\n",
      "train loss:0.030808405495542847\n",
      "train loss:0.06900833111346524\n",
      "train loss:0.07702539476979701\n",
      "train loss:0.041712330185397\n",
      "train loss:0.08815416783818644\n",
      "train loss:0.04580500262552431\n",
      "train loss:0.04593815627208581\n",
      "train loss:0.03419688083215997\n",
      "train loss:0.06592043291170537\n",
      "train loss:0.01979466925979701\n",
      "train loss:0.045368466282101914\n",
      "train loss:0.021300329581011235\n",
      "train loss:0.08797844299361175\n",
      "train loss:0.010816546411707161\n",
      "train loss:0.1032209695001132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0655361150357903\n",
      "train loss:0.020452328088670292\n",
      "train loss:0.04279445084617163\n",
      "train loss:0.015867699762505034\n",
      "train loss:0.02055074575720651\n",
      "train loss:0.09028689164156331\n",
      "train loss:0.14610920784573053\n",
      "train loss:0.0882887323379146\n",
      "train loss:0.16267879049050119\n",
      "train loss:0.012561119975105183\n",
      "train loss:0.19524476950810463\n",
      "train loss:0.07496966900747487\n",
      "train loss:0.12810422871138466\n",
      "train loss:0.08929994703618332\n",
      "train loss:0.11216795343312239\n",
      "train loss:0.030620462826989686\n",
      "train loss:0.05649888821542451\n",
      "train loss:0.113724203938479\n",
      "train loss:0.05051318477882538\n",
      "train loss:0.0832374127104236\n",
      "train loss:0.11693843548944853\n",
      "train loss:0.0906689576482031\n",
      "train loss:0.05516936006839787\n",
      "train loss:0.07138057582467142\n",
      "train loss:0.051786147741093906\n",
      "train loss:0.05513818068049063\n",
      "train loss:0.049499982106476076\n",
      "train loss:0.03423181091403056\n",
      "train loss:0.19822060787670776\n",
      "train loss:0.09190830218601727\n",
      "train loss:0.07335271421641289\n",
      "train loss:0.036535225596698216\n",
      "train loss:0.07476719184408989\n",
      "train loss:0.07211717196786843\n",
      "train loss:0.05538036161801324\n",
      "train loss:0.04711002685397833\n",
      "train loss:0.14152425859274081\n",
      "train loss:0.07566915286909684\n",
      "train loss:0.04349430231322551\n",
      "train loss:0.07304745595757235\n",
      "train loss:0.042757184716847876\n",
      "train loss:0.0449210161394274\n",
      "train loss:0.060585597154492875\n",
      "train loss:0.08642811376998619\n",
      "train loss:0.02616134463278605\n",
      "train loss:0.09078602114827802\n",
      "train loss:0.046163359334976256\n",
      "train loss:0.03784362874345939\n",
      "train loss:0.06414480755121887\n",
      "train loss:0.11820678992868924\n",
      "train loss:0.09794449709116476\n",
      "train loss:0.026887032837145854\n",
      "train loss:0.10669780836847195\n",
      "train loss:0.14786692573858973\n",
      "train loss:0.1239848981027713\n",
      "train loss:0.024137902471674112\n",
      "train loss:0.06456772627799193\n",
      "train loss:0.07255174210763442\n",
      "train loss:0.0689959856456188\n",
      "train loss:0.04225182204690853\n",
      "train loss:0.06880310456586151\n",
      "train loss:0.09297546536838974\n",
      "train loss:0.06708286499892405\n",
      "train loss:0.06724860121983203\n",
      "train loss:0.08683799688261944\n",
      "train loss:0.10293676688768232\n",
      "train loss:0.07375490257325626\n",
      "train loss:0.05604813973672942\n",
      "train loss:0.03679041521822936\n",
      "train loss:0.0357794318468272\n",
      "train loss:0.03788458258973588\n",
      "train loss:0.06191889696523976\n",
      "train loss:0.050939690554805496\n",
      "train loss:0.029783678311828484\n",
      "train loss:0.0890272151159507\n",
      "train loss:0.06680864205436686\n",
      "train loss:0.04813770458493833\n",
      "train loss:0.09967711345206327\n",
      "train loss:0.09863321222722565\n",
      "train loss:0.2199693839458491\n",
      "train loss:0.04659766457130386\n",
      "train loss:0.05058578275403696\n",
      "train loss:0.110969307943577\n",
      "train loss:0.05545020674294264\n",
      "train loss:0.12090219721376778\n",
      "train loss:0.032944518937973545\n",
      "train loss:0.03833984320617286\n",
      "train loss:0.1402409762394198\n",
      "train loss:0.06071884817761851\n",
      "train loss:0.0329932232433446\n",
      "train loss:0.08491775543483775\n",
      "train loss:0.04047327422244436\n",
      "train loss:0.04925989731170957\n",
      "train loss:0.06395823451652886\n",
      "train loss:0.02840930902449465\n",
      "train loss:0.039044297620435715\n",
      "train loss:0.025362690789126615\n",
      "train loss:0.07011841828357217\n",
      "train loss:0.10786543266387585\n",
      "train loss:0.08991240070845195\n",
      "train loss:0.052727416330644185\n",
      "train loss:0.0786494516641411\n",
      "train loss:0.042271479846302765\n",
      "train loss:0.03427961510391466\n",
      "train loss:0.06648361755034127\n",
      "train loss:0.04528383262796178\n",
      "train loss:0.0912419618953065\n",
      "train loss:0.028235644404267467\n",
      "train loss:0.09546785735979123\n",
      "train loss:0.06080428384463582\n",
      "train loss:0.07244669703313644\n",
      "train loss:0.1819934646902466\n",
      "train loss:0.11103434407583461\n",
      "train loss:0.061506601609222174\n",
      "train loss:0.10378323669230405\n",
      "train loss:0.05683142666887202\n",
      "train loss:0.017210822681199743\n",
      "train loss:0.052237408282002226\n",
      "train loss:0.09619283311240925\n",
      "train loss:0.12401555631818727\n",
      "train loss:0.12127270001742868\n",
      "train loss:0.09053648860399001\n",
      "train loss:0.08376296020383375\n",
      "train loss:0.03464140545130747\n",
      "train loss:0.02934605697789896\n",
      "train loss:0.08288941604697231\n",
      "train loss:0.1621724886657822\n",
      "train loss:0.06289998460839508\n",
      "train loss:0.08373978534865714\n",
      "train loss:0.035379791585094675\n",
      "train loss:0.04925909031174691\n",
      "train loss:0.02397380618660495\n",
      "train loss:0.11909174698724921\n",
      "train loss:0.04751493786877937\n",
      "train loss:0.03454227330897959\n",
      "train loss:0.06461600422077271\n",
      "train loss:0.03543422185776278\n",
      "train loss:0.07800352865636961\n",
      "train loss:0.1158244162623828\n",
      "train loss:0.12835764310112213\n",
      "train loss:0.026696857824630053\n",
      "train loss:0.07422473461041243\n",
      "train loss:0.025628549552317442\n",
      "train loss:0.033796559864449106\n",
      "train loss:0.07820327924685123\n",
      "train loss:0.041672082232868855\n",
      "train loss:0.07922551557404799\n",
      "train loss:0.1707553583084432\n",
      "train loss:0.11875431222436665\n",
      "train loss:0.04767455577762956\n",
      "train loss:0.04180029131692519\n",
      "train loss:0.03994890945932389\n",
      "train loss:0.06343960675963035\n",
      "train loss:0.032534722375036094\n",
      "train loss:0.09167329117794894\n",
      "train loss:0.12481675424308075\n",
      "train loss:0.029346093682146406\n",
      "train loss:0.08767453517422012\n",
      "train loss:0.08252189138987853\n",
      "train loss:0.06162579959005958\n",
      "train loss:0.19235784742798706\n",
      "train loss:0.10764280101664647\n",
      "train loss:0.15550326496038488\n",
      "train loss:0.15527075561850792\n",
      "train loss:0.023173537921375047\n",
      "train loss:0.06775777656307103\n",
      "train loss:0.041137432931577636\n",
      "train loss:0.04270210556654077\n",
      "train loss:0.02144465849276998\n",
      "train loss:0.04340537930919288\n",
      "train loss:0.10434357955972827\n",
      "train loss:0.09302047426222453\n",
      "train loss:0.10356683860549198\n",
      "train loss:0.05827588165046335\n",
      "train loss:0.08255740247125049\n",
      "train loss:0.025380808784074057\n",
      "train loss:0.03889538176465555\n",
      "train loss:0.04792412351831077\n",
      "train loss:0.04448936793184683\n",
      "train loss:0.06013313716756608\n",
      "train loss:0.09597942207153626\n",
      "train loss:0.124348933193212\n",
      "train loss:0.09115974978026173\n",
      "train loss:0.03936508318160472\n",
      "train loss:0.06550642422124309\n",
      "train loss:0.0549297077073074\n",
      "train loss:0.11644365652721095\n",
      "train loss:0.058695868744317856\n",
      "train loss:0.04863973281134361\n",
      "train loss:0.03742884370487855\n",
      "train loss:0.06961823236547335\n",
      "train loss:0.03815296289298572\n",
      "train loss:0.05068343619734701\n",
      "train loss:0.048591007599090436\n",
      "train loss:0.03927993955979158\n",
      "train loss:0.029472713335018684\n",
      "train loss:0.045926872348682056\n",
      "train loss:0.07736909082658838\n",
      "train loss:0.0187214525502912\n",
      "train loss:0.07956239708358356\n",
      "train loss:0.07793730252702175\n",
      "train loss:0.021428717871443837\n",
      "train loss:0.027505742174034408\n",
      "train loss:0.05166361866798312\n",
      "train loss:0.1387922589599303\n",
      "train loss:0.010693654778422063\n",
      "train loss:0.0785361721311625\n",
      "train loss:0.031242217779445833\n",
      "train loss:0.05769031176820806\n",
      "train loss:0.08117583425800566\n",
      "train loss:0.033464634675089554\n",
      "train loss:0.07668295450709656\n",
      "train loss:0.022585422823266584\n",
      "train loss:0.14492181677089078\n",
      "train loss:0.16721637534848235\n",
      "train loss:0.012741292421976635\n",
      "train loss:0.09090748313153668\n",
      "train loss:0.11544164392215471\n",
      "train loss:0.023999054154162994\n",
      "train loss:0.04843850129908683\n",
      "train loss:0.072179460182247\n",
      "train loss:0.16488310474251136\n",
      "train loss:0.04238387974371447\n",
      "train loss:0.040298198434294046\n",
      "train loss:0.08372596614313593\n",
      "train loss:0.08746044721672694\n",
      "train loss:0.04237985957048997\n",
      "train loss:0.05549112046352663\n",
      "train loss:0.06504821532780465\n",
      "train loss:0.07913934452454312\n",
      "train loss:0.11972036928349851\n",
      "train loss:0.038459979727800936\n",
      "train loss:0.041584042708833736\n",
      "train loss:0.062224212199211204\n",
      "train loss:0.039891490754858865\n",
      "train loss:0.024271391624667214\n",
      "train loss:0.12494103062286475\n",
      "train loss:0.10673657056937307\n",
      "train loss:0.03952586509026196\n",
      "train loss:0.031232071220422125\n",
      "train loss:0.1672846859089959\n",
      "train loss:0.11289522494156642\n",
      "train loss:0.025377624380741072\n",
      "train loss:0.11088504798300461\n",
      "train loss:0.058164117332368065\n",
      "train loss:0.03219149148996567\n",
      "train loss:0.04432031481578806\n",
      "train loss:0.04940673947963285\n",
      "train loss:0.01958143647421797\n",
      "train loss:0.04053019707221901\n",
      "train loss:0.05774412187874743\n",
      "train loss:0.05072623290684012\n",
      "train loss:0.07524736226431211\n",
      "train loss:0.038848848305416954\n",
      "train loss:0.030760523722404353\n",
      "train loss:0.07289836196350946\n",
      "train loss:0.023836741623001808\n",
      "train loss:0.09866248427256394\n",
      "train loss:0.13016524121081258\n",
      "train loss:0.045957171447758786\n",
      "train loss:0.09434000925583465\n",
      "train loss:0.022015490733217197\n",
      "train loss:0.13287502999826709\n",
      "train loss:0.05092979237149963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0430952915361162\n",
      "train loss:0.08199945755701435\n",
      "train loss:0.04916090051736332\n",
      "train loss:0.08025160751529181\n",
      "train loss:0.026951459643397596\n",
      "train loss:0.043594841200574025\n",
      "train loss:0.042923943570619516\n",
      "train loss:0.09909842199480336\n",
      "train loss:0.06115230268070668\n",
      "train loss:0.06056273740584208\n",
      "train loss:0.06807790284797162\n",
      "train loss:0.12039512867629469\n",
      "train loss:0.03635147099868428\n",
      "train loss:0.18265914712695167\n",
      "train loss:0.03261726929090131\n",
      "train loss:0.027344439878954723\n",
      "train loss:0.022178537182599344\n",
      "train loss:0.04043188316656366\n",
      "train loss:0.05358773774859883\n",
      "train loss:0.05736452690834982\n",
      "train loss:0.03161715626802594\n",
      "train loss:0.03212691566022697\n",
      "train loss:0.06864375110411727\n",
      "train loss:0.06429832112036384\n",
      "train loss:0.07001304997435129\n",
      "train loss:0.06247263436873267\n",
      "train loss:0.10658505480361148\n",
      "train loss:0.12580418049506797\n",
      "train loss:0.04774116123939193\n",
      "train loss:0.10141217570111025\n",
      "train loss:0.0349536022948361\n",
      "train loss:0.04023371121970642\n",
      "train loss:0.022845748491150807\n",
      "train loss:0.1470246658991314\n",
      "train loss:0.0398716339106041\n",
      "train loss:0.03766304434521321\n",
      "train loss:0.017681540923779267\n",
      "train loss:0.14235017596272123\n",
      "train loss:0.06577181986123762\n",
      "train loss:0.11980064656079352\n",
      "train loss:0.030508836312112157\n",
      "train loss:0.028699833040271988\n",
      "train loss:0.05400816563431765\n",
      "train loss:0.023059918570560042\n",
      "train loss:0.05015849530363861\n",
      "train loss:0.08014430424458636\n",
      "train loss:0.05859933061991589\n",
      "train loss:0.0373826740273531\n",
      "train loss:0.07468401187517712\n",
      "train loss:0.03316021057112428\n",
      "train loss:0.13760183740498058\n",
      "train loss:0.16576464174401045\n",
      "train loss:0.12209790885822157\n",
      "train loss:0.05147363454087363\n",
      "train loss:0.04038365730614797\n",
      "train loss:0.018539140665290266\n",
      "train loss:0.041762595725982676\n",
      "train loss:0.1945529823964695\n",
      "train loss:0.10879446119385364\n",
      "train loss:0.04527730691170469\n",
      "train loss:0.02049011691406911\n",
      "train loss:0.033890405957469165\n",
      "train loss:0.023438868190235745\n",
      "train loss:0.08145974700276953\n",
      "train loss:0.08598047946952324\n",
      "train loss:0.046864250544830476\n",
      "train loss:0.04696455241087025\n",
      "train loss:0.043984074496517284\n",
      "train loss:0.01763591670385207\n",
      "train loss:0.04714381730317889\n",
      "train loss:0.08022985593430552\n",
      "train loss:0.12525622505968223\n",
      "train loss:0.041267149857601916\n",
      "train loss:0.04669574604306928\n",
      "train loss:0.024786735767183977\n",
      "train loss:0.03534381781438256\n",
      "train loss:0.056073679760590245\n",
      "train loss:0.039750126212847965\n",
      "train loss:0.06949286565863354\n",
      "train loss:0.039179419605073644\n",
      "train loss:0.07789736196494473\n",
      "train loss:0.09106576049767914\n",
      "train loss:0.034790050430621\n",
      "train loss:0.11725812776311571\n",
      "train loss:0.06242718162495083\n",
      "train loss:0.039103390721381685\n",
      "train loss:0.07439150142365178\n",
      "train loss:0.0477541012883938\n",
      "train loss:0.14501517971160388\n",
      "train loss:0.033978886968116635\n",
      "train loss:0.05005406851592412\n",
      "train loss:0.0661621069820261\n",
      "train loss:0.05490299522274603\n",
      "train loss:0.05185415949524255\n",
      "train loss:0.07921262748287339\n",
      "train loss:0.07462664754660973\n",
      "train loss:0.027672027483544418\n",
      "train loss:0.0383647872977258\n",
      "train loss:0.0902358183721926\n",
      "train loss:0.055173896069230885\n",
      "train loss:0.06910919685432222\n",
      "train loss:0.038207022175918405\n",
      "train loss:0.17135706642138324\n",
      "train loss:0.0894000863551177\n",
      "train loss:0.0454648527354438\n",
      "train loss:0.041459034342457624\n",
      "train loss:0.048423768375373724\n",
      "train loss:0.08991656893013303\n",
      "train loss:0.02044227988871878\n",
      "train loss:0.03239699131435128\n",
      "train loss:0.024014435792687038\n",
      "train loss:0.03798942082029678\n",
      "train loss:0.0515172524168812\n",
      "train loss:0.04687810574884378\n",
      "train loss:0.04700171077607287\n",
      "train loss:0.042124879609282656\n",
      "train loss:0.1484857502118116\n",
      "train loss:0.06212399980765678\n",
      "train loss:0.02764175217086757\n",
      "train loss:0.038286266237827014\n",
      "train loss:0.015780244955561854\n",
      "train loss:0.0455113550806443\n",
      "train loss:0.042137768018143465\n",
      "train loss:0.06494654399680974\n",
      "train loss:0.04748635852923532\n",
      "train loss:0.04799320523346354\n",
      "train loss:0.05748833403792171\n",
      "train loss:0.04487021741583211\n",
      "train loss:0.04604600310910438\n",
      "train loss:0.07561648138752436\n",
      "train loss:0.09882707831159525\n",
      "train loss:0.06768879439958186\n",
      "train loss:0.03019335163467842\n",
      "train loss:0.05935293844468041\n",
      "train loss:0.081987596595687\n",
      "train loss:0.08318132851131375\n",
      "train loss:0.19364873439163993\n",
      "train loss:0.027924548384886404\n",
      "train loss:0.05681996461812533\n",
      "train loss:0.051674303438844583\n",
      "train loss:0.07714042306693654\n",
      "train loss:0.08905877687181554\n",
      "train loss:0.03577594554104854\n",
      "train loss:0.09196843750728695\n",
      "train loss:0.036774947744888195\n",
      "train loss:0.042369885657222175\n",
      "train loss:0.0546217811564351\n",
      "train loss:0.0714643985310522\n",
      "train loss:0.04489047072975139\n",
      "train loss:0.06841963314532626\n",
      "train loss:0.05796926000091168\n",
      "train loss:0.1358057500521435\n",
      "train loss:0.08306296537582919\n",
      "train loss:0.1116190212738425\n",
      "train loss:0.01545947430685096\n",
      "train loss:0.09801032236146877\n",
      "train loss:0.09749296246516498\n",
      "train loss:0.044992979015620674\n",
      "train loss:0.08782212668892814\n",
      "train loss:0.10054711203738917\n",
      "train loss:0.033051705477465165\n",
      "train loss:0.05229961025075778\n",
      "train loss:0.04241500288194239\n",
      "train loss:0.12144967393420916\n",
      "train loss:0.12370462477004703\n",
      "train loss:0.02560694178855238\n",
      "train loss:0.042122922255361406\n",
      "train loss:0.019838298829960698\n",
      "train loss:0.077528207066266\n",
      "train loss:0.03671995883504213\n",
      "train loss:0.01957500227914085\n",
      "train loss:0.08709360984209841\n",
      "train loss:0.04526255937774557\n",
      "train loss:0.05416179537298456\n",
      "train loss:0.10400686422985976\n",
      "train loss:0.019639192276189876\n",
      "train loss:0.03367516671055253\n",
      "train loss:0.06890550395605735\n",
      "train loss:0.038115138621502766\n",
      "train loss:0.047499660015141394\n",
      "train loss:0.0793633321021265\n",
      "train loss:0.015859011987115763\n",
      "train loss:0.035674506896142766\n",
      "train loss:0.04787258367211577\n",
      "train loss:0.03744870109996471\n",
      "train loss:0.025557319563484795\n",
      "train loss:0.09471914960893738\n",
      "train loss:0.018472910420894183\n",
      "train loss:0.17885763407801608\n",
      "train loss:0.03948020426959798\n",
      "train loss:0.06281932858063465\n",
      "train loss:0.0774938079865841\n",
      "train loss:0.045656171497297275\n",
      "train loss:0.11199622182459672\n",
      "train loss:0.1596456583200786\n",
      "train loss:0.0311654680921427\n",
      "train loss:0.028434662220480935\n",
      "train loss:0.09369094086338815\n",
      "train loss:0.05642458553258179\n",
      "train loss:0.1599442341968837\n",
      "train loss:0.033973455683912225\n",
      "train loss:0.12855969363128955\n",
      "train loss:0.15904333251454375\n",
      "train loss:0.10253467956475674\n",
      "train loss:0.06436402139304598\n",
      "train loss:0.01779336864696608\n",
      "train loss:0.040520483899990446\n",
      "train loss:0.05452951754690195\n",
      "train loss:0.05841609995800409\n",
      "train loss:0.040121116574139214\n",
      "train loss:0.040083727504267676\n",
      "train loss:0.09297988496078709\n",
      "train loss:0.08589899487180411\n",
      "train loss:0.16012941781389592\n",
      "train loss:0.02523076756532844\n",
      "train loss:0.10172598626248164\n",
      "train loss:0.024459501518967\n",
      "train loss:0.03400199693451388\n",
      "train loss:0.03254245899486673\n",
      "train loss:0.1222590340115342\n",
      "train loss:0.01624961820095642\n",
      "train loss:0.04778844400581577\n",
      "train loss:0.03076040781067191\n",
      "train loss:0.02401407799883286\n",
      "train loss:0.06168633097358092\n",
      "train loss:0.06382901668164907\n",
      "train loss:0.06774680168788896\n",
      "train loss:0.08391130378301309\n",
      "train loss:0.09841902847847123\n",
      "train loss:0.0957328967375375\n",
      "train loss:0.08767940712073606\n",
      "train loss:0.0535757254376284\n",
      "train loss:0.09338182849204861\n",
      "train loss:0.017843273369266784\n",
      "train loss:0.028599592939466158\n",
      "train loss:0.01765746193939843\n",
      "train loss:0.013475451821765431\n",
      "train loss:0.1195442569059765\n",
      "train loss:0.033713980600134065\n",
      "train loss:0.04605836117560996\n",
      "train loss:0.03553943502070036\n",
      "train loss:0.012329713723254641\n",
      "train loss:0.09279646737590573\n",
      "train loss:0.04572644836230354\n",
      "train loss:0.023288072373852484\n",
      "train loss:0.03793859450519459\n",
      "train loss:0.02621975240792585\n",
      "train loss:0.025338434100030355\n",
      "train loss:0.0567631513608507\n",
      "train loss:0.03096023443873418\n",
      "train loss:0.010336227045386613\n",
      "train loss:0.10277536848094904\n",
      "train loss:0.04795088761609332\n",
      "train loss:0.07257489566234553\n",
      "train loss:0.03838807129773411\n",
      "train loss:0.14158969864165985\n",
      "train loss:0.011795457473473983\n",
      "train loss:0.12288109418349132\n",
      "train loss:0.04431664732714321\n",
      "train loss:0.026960844264608028\n",
      "train loss:0.033694157732348136\n",
      "train loss:0.08841293555189468\n",
      "train loss:0.055033490821904035\n",
      "train loss:0.11715664170435046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0775532720691152\n",
      "train loss:0.11000393454113533\n",
      "train loss:0.04005742410600711\n",
      "train loss:0.06921416810123737\n",
      "train loss:0.06119981679502559\n",
      "train loss:0.14770917329795913\n",
      "train loss:0.043928365915009475\n",
      "train loss:0.06855577467435645\n",
      "train loss:0.06421675396646286\n",
      "train loss:0.0694481796074382\n",
      "train loss:0.0325059388453778\n",
      "=== epoch:5, train acc:0.978, test acc:0.976 ===\n",
      "train loss:0.04384495964752176\n",
      "train loss:0.06525034598524883\n",
      "train loss:0.05433564471627451\n",
      "train loss:0.0253775948042307\n",
      "train loss:0.035524397038023126\n",
      "train loss:0.03298483866349029\n",
      "train loss:0.07794618053749126\n",
      "train loss:0.017524860406187337\n",
      "train loss:0.0527402399159717\n",
      "train loss:0.0352176314632915\n",
      "train loss:0.009521128337199064\n",
      "train loss:0.04973289350695746\n",
      "train loss:0.02878031372841513\n",
      "train loss:0.04989164752758711\n",
      "train loss:0.05263509888097348\n",
      "train loss:0.02380087019066879\n",
      "train loss:0.016795446965656467\n",
      "train loss:0.08966634040395592\n",
      "train loss:0.05916569046859502\n",
      "train loss:0.024886220546383283\n",
      "train loss:0.068541419830922\n",
      "train loss:0.06049708320070099\n",
      "train loss:0.04459157058612391\n",
      "train loss:0.06606634983091238\n",
      "train loss:0.02076743846751565\n",
      "train loss:0.057061576797867365\n",
      "train loss:0.052870865352489256\n",
      "train loss:0.02457242267591499\n",
      "train loss:0.03193973491796412\n",
      "train loss:0.10918002897282138\n",
      "train loss:0.027799328937772944\n",
      "train loss:0.113275874885857\n",
      "train loss:0.02285441789037805\n",
      "train loss:0.115295736418282\n",
      "train loss:0.09374827464255427\n",
      "train loss:0.022019593071497482\n",
      "train loss:0.028304161125083\n",
      "train loss:0.04944900753295107\n",
      "train loss:0.03613836555355273\n",
      "train loss:0.07962550469878056\n",
      "train loss:0.0751405552560615\n",
      "train loss:0.020977370776452703\n",
      "train loss:0.019959015017791345\n",
      "train loss:0.03080877019489701\n",
      "train loss:0.08542129892450417\n",
      "train loss:0.015563552095929705\n",
      "train loss:0.02887150109522578\n",
      "train loss:0.03284905996018493\n",
      "train loss:0.037871403245268394\n",
      "train loss:0.0179671075386359\n",
      "train loss:0.06013310949796928\n",
      "train loss:0.050564919200147954\n",
      "train loss:0.02239724484846312\n",
      "train loss:0.10411680000177757\n",
      "train loss:0.03589338603779561\n",
      "train loss:0.09391578874053146\n",
      "train loss:0.05588320562508103\n",
      "train loss:0.04663230554122683\n",
      "train loss:0.019103083952421128\n",
      "train loss:0.03591845462197956\n",
      "train loss:0.09218021269270542\n",
      "train loss:0.09875658129806458\n",
      "train loss:0.049523492518549005\n",
      "train loss:0.03626826447952852\n",
      "train loss:0.013782176015520571\n",
      "train loss:0.0567416958079531\n",
      "train loss:0.10916157243163754\n",
      "train loss:0.08546884881612388\n",
      "train loss:0.08806377635896379\n",
      "train loss:0.1334137803954141\n",
      "train loss:0.06438096754913963\n",
      "train loss:0.11877496972323685\n",
      "train loss:0.058454280234470246\n",
      "train loss:0.02909925491018253\n",
      "train loss:0.03547805285072206\n",
      "train loss:0.051718867363447885\n",
      "train loss:0.05813835030067383\n",
      "train loss:0.03801263911214264\n",
      "train loss:0.05243830877533998\n",
      "train loss:0.05464449722617367\n",
      "train loss:0.05794763146683207\n",
      "train loss:0.027705570434538536\n",
      "train loss:0.032085792558090936\n",
      "train loss:0.07840013801053003\n",
      "train loss:0.07823759862397328\n",
      "train loss:0.06011153326489007\n",
      "train loss:0.020967639765211127\n",
      "train loss:0.04444648969674958\n",
      "train loss:0.02990243962422594\n",
      "train loss:0.06248755028076225\n",
      "train loss:0.02347678655203926\n",
      "train loss:0.03606843680303682\n",
      "train loss:0.0363333307453332\n",
      "train loss:0.06197581243051784\n",
      "train loss:0.10475737357380481\n",
      "train loss:0.06682979482399601\n",
      "train loss:0.03687005845083248\n",
      "train loss:0.057406217078329116\n",
      "train loss:0.04534382522842981\n",
      "train loss:0.022050173838158275\n",
      "train loss:0.14311291819229363\n",
      "train loss:0.06323008233330919\n",
      "train loss:0.05031567092542405\n",
      "train loss:0.0545995780179297\n",
      "train loss:0.057754586837011165\n",
      "train loss:0.040798253307570274\n",
      "train loss:0.0591053672399338\n",
      "train loss:0.09533571530840831\n",
      "train loss:0.05010632500949209\n",
      "train loss:0.08770167129998606\n",
      "train loss:0.08235157959765312\n",
      "train loss:0.038325905136563414\n",
      "train loss:0.018322436595488746\n",
      "train loss:0.06317850888229282\n",
      "train loss:0.031791037534314975\n",
      "train loss:0.06280902927595179\n",
      "train loss:0.032943733078022605\n",
      "train loss:0.02101427336694173\n",
      "train loss:0.012980697133652457\n",
      "train loss:0.08273616797087793\n",
      "train loss:0.07540143812247943\n",
      "train loss:0.08219855675070177\n",
      "train loss:0.044390176359829274\n",
      "train loss:0.047554660623886205\n",
      "train loss:0.03713233759416764\n",
      "train loss:0.08034422072334584\n",
      "train loss:0.06134590717366426\n",
      "train loss:0.02169270804608743\n",
      "train loss:0.18467410583828908\n",
      "train loss:0.01858698911878331\n",
      "train loss:0.021017710369813893\n",
      "train loss:0.16716819725696197\n",
      "train loss:0.1386076757875901\n",
      "train loss:0.025039691613635853\n",
      "train loss:0.04370252694947021\n",
      "train loss:0.06104026412002923\n",
      "train loss:0.017573194985055853\n",
      "train loss:0.047945195390001735\n",
      "train loss:0.020966060302896942\n",
      "train loss:0.029207277404700943\n",
      "train loss:0.0406350340479422\n",
      "train loss:0.009226936527221924\n",
      "train loss:0.02716142653415626\n",
      "train loss:0.03721157722275295\n",
      "train loss:0.040758566001076545\n",
      "train loss:0.0345219153787494\n",
      "train loss:0.028148891494824187\n",
      "train loss:0.10413211884100067\n",
      "train loss:0.06590293824376832\n",
      "train loss:0.02877386803964442\n",
      "train loss:0.1304385843892081\n",
      "train loss:0.012648426300266595\n",
      "train loss:0.10270952357257344\n",
      "train loss:0.10721858589639029\n",
      "train loss:0.033984534968919476\n",
      "train loss:0.03939001147272278\n",
      "train loss:0.05427094662340223\n",
      "train loss:0.09538689466716863\n",
      "train loss:0.021108132090114067\n",
      "train loss:0.01684760417423182\n",
      "train loss:0.04728992691599796\n",
      "train loss:0.027257083042092324\n",
      "train loss:0.03749414510664174\n",
      "train loss:0.03222453407498376\n",
      "train loss:0.052790146309026446\n",
      "train loss:0.05257369686374598\n",
      "train loss:0.055454096739337606\n",
      "train loss:0.07758101109635836\n",
      "train loss:0.014070010052827917\n",
      "train loss:0.05088394758538322\n",
      "train loss:0.06505252718009062\n",
      "train loss:0.013769949838367207\n",
      "train loss:0.1338951355083775\n",
      "train loss:0.08318520115337949\n",
      "train loss:0.09541054137622564\n",
      "train loss:0.057404407736086356\n",
      "train loss:0.04577602539269767\n",
      "train loss:0.04441457504904678\n",
      "train loss:0.015038585146185699\n",
      "train loss:0.027493815084829336\n",
      "train loss:0.05282037053315824\n",
      "train loss:0.06487464564993797\n",
      "train loss:0.04357453626098974\n",
      "train loss:0.05165497697964756\n",
      "train loss:0.024849245176290394\n",
      "train loss:0.012124966226326663\n",
      "train loss:0.09432284197962043\n",
      "train loss:0.04375985233961147\n",
      "train loss:0.02106440373103294\n",
      "train loss:0.07978674271612697\n",
      "train loss:0.02205084409915906\n",
      "train loss:0.020228373877516633\n",
      "train loss:0.030100668939420035\n",
      "train loss:0.03459211034388847\n",
      "train loss:0.0965080923736706\n",
      "train loss:0.027160779363189936\n",
      "train loss:0.06367314148759715\n",
      "train loss:0.0634836275993119\n",
      "train loss:0.05801650969862075\n",
      "train loss:0.018179387576853313\n",
      "train loss:0.018285300892771406\n",
      "train loss:0.06872165767916985\n",
      "train loss:0.030931480695457765\n",
      "train loss:0.026581001846560714\n",
      "train loss:0.034592947708504906\n",
      "train loss:0.0808051089751964\n",
      "train loss:0.056430792328123563\n",
      "train loss:0.038035750272274446\n",
      "train loss:0.03747468608551553\n",
      "train loss:0.032501593018579474\n",
      "train loss:0.0730361012684543\n",
      "train loss:0.08110617388896181\n",
      "train loss:0.04812554411274235\n",
      "train loss:0.03671047017640038\n",
      "train loss:0.0913349889026357\n",
      "train loss:0.03297628283712081\n",
      "train loss:0.009270746099351246\n",
      "train loss:0.015985674914284365\n",
      "train loss:0.017539250188659608\n",
      "train loss:0.03231781329974144\n",
      "train loss:0.07714059052473993\n",
      "train loss:0.034210178401982747\n",
      "train loss:0.058629141099606874\n",
      "train loss:0.19362113154800958\n",
      "train loss:0.010174729326678447\n",
      "train loss:0.07373436606609421\n",
      "train loss:0.025050523429413704\n",
      "train loss:0.0757681537507315\n",
      "train loss:0.06320883767000045\n",
      "train loss:0.028452980135549942\n",
      "train loss:0.12907942885427395\n",
      "train loss:0.017478209265239006\n",
      "train loss:0.03809488383582851\n",
      "train loss:0.014825077537855886\n",
      "train loss:0.020857833409074975\n",
      "train loss:0.04374278580506023\n",
      "train loss:0.04185779732722652\n",
      "train loss:0.07403810523834925\n",
      "train loss:0.031028281012368784\n",
      "train loss:0.028303685857343504\n",
      "train loss:0.011053292277796136\n",
      "train loss:0.050307314451602504\n",
      "train loss:0.06167988358212588\n",
      "train loss:0.12461815077927536\n",
      "train loss:0.07952855175671136\n",
      "train loss:0.03508711029775152\n",
      "train loss:0.01877158215072247\n",
      "train loss:0.007165436229704404\n",
      "train loss:0.07873921395701566\n",
      "train loss:0.09060750108662056\n",
      "train loss:0.02648663031395154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006241669591302186\n",
      "train loss:0.01729676720668519\n",
      "train loss:0.024253868839445532\n",
      "train loss:0.02608262756540255\n",
      "train loss:0.05456059485214748\n",
      "train loss:0.02046671499426619\n",
      "train loss:0.07315042187044458\n",
      "train loss:0.008973631441799333\n",
      "train loss:0.07593059633813351\n",
      "train loss:0.01345425285836893\n",
      "train loss:0.04867550621545637\n",
      "train loss:0.06984509938855878\n",
      "train loss:0.044231947055755096\n",
      "train loss:0.028278049471483983\n",
      "train loss:0.012691676558924893\n",
      "train loss:0.026153667306771707\n",
      "train loss:0.029491062165742803\n",
      "train loss:0.0689006137978651\n",
      "train loss:0.018152470990659392\n",
      "train loss:0.08136827048094171\n",
      "train loss:0.012803519214037164\n",
      "train loss:0.0064616396946913035\n",
      "train loss:0.016059685622595212\n",
      "train loss:0.021190609402597184\n",
      "train loss:0.038972804486014506\n",
      "train loss:0.021658705641276997\n",
      "train loss:0.02647697995748179\n",
      "train loss:0.009755717144509669\n",
      "train loss:0.009982821728893653\n",
      "train loss:0.043600097643964976\n",
      "train loss:0.023060593993967222\n",
      "train loss:0.016204001701062176\n",
      "train loss:0.01988801987147343\n",
      "train loss:0.013363286778549055\n",
      "train loss:0.04528417602220556\n",
      "train loss:0.14253529323605557\n",
      "train loss:0.09374898323274446\n",
      "train loss:0.00969943128911333\n",
      "train loss:0.026841832261827996\n",
      "train loss:0.07894520309667893\n",
      "train loss:0.04424695564753829\n",
      "train loss:0.0146989246470666\n",
      "train loss:0.04319768793453517\n",
      "train loss:0.049492553015421346\n",
      "train loss:0.09137448456834392\n",
      "train loss:0.025299399928073757\n",
      "train loss:0.013303800906608307\n",
      "train loss:0.032470023240733725\n",
      "train loss:0.07312954310074747\n",
      "train loss:0.011998488778562456\n",
      "train loss:0.07661650371482347\n",
      "train loss:0.07741544484011328\n",
      "train loss:0.026173110136362084\n",
      "train loss:0.035442272822060764\n",
      "train loss:0.04046480594276068\n",
      "train loss:0.05323141557259991\n",
      "train loss:0.016457920909263245\n",
      "train loss:0.02625831366847895\n",
      "train loss:0.029527797433687383\n",
      "train loss:0.036866479294647786\n",
      "train loss:0.0779265378852268\n",
      "train loss:0.04017409288543705\n",
      "train loss:0.0378755326167495\n",
      "train loss:0.06985666095628967\n",
      "train loss:0.04342587434033291\n",
      "train loss:0.035249008553630286\n",
      "train loss:0.04509723294251743\n",
      "train loss:0.043357663978943355\n",
      "train loss:0.06402581704951692\n",
      "train loss:0.14612358179203924\n",
      "train loss:0.02392058757550692\n",
      "train loss:0.06113782502312353\n",
      "train loss:0.025647943658599365\n",
      "train loss:0.02689885227086779\n",
      "train loss:0.019507349930481695\n",
      "train loss:0.02662787545729553\n",
      "train loss:0.01715052010218404\n",
      "train loss:0.04332808242501482\n",
      "train loss:0.07540199329674362\n",
      "train loss:0.06054578178189215\n",
      "train loss:0.03576159068061821\n",
      "train loss:0.03138676947180247\n",
      "train loss:0.04356219247576564\n",
      "train loss:0.03670085860797378\n",
      "train loss:0.01683803141130308\n",
      "train loss:0.033520088503086125\n",
      "train loss:0.021878934812886545\n",
      "train loss:0.03541568534940742\n",
      "train loss:0.04599970559197595\n",
      "train loss:0.011400301401156674\n",
      "train loss:0.09426087796980688\n",
      "train loss:0.10440847616436981\n",
      "train loss:0.014749724714676903\n",
      "train loss:0.02328347101699456\n",
      "train loss:0.23148035601166161\n",
      "train loss:0.03402250531009053\n",
      "train loss:0.020325386881004225\n",
      "train loss:0.04626151163541262\n",
      "train loss:0.05167353279751146\n",
      "train loss:0.07208222157200732\n",
      "train loss:0.05741780742264929\n",
      "train loss:0.05065244513030478\n",
      "train loss:0.04089467317200584\n",
      "train loss:0.02528335586297942\n",
      "train loss:0.03564526505104235\n",
      "train loss:0.07146207835552289\n",
      "train loss:0.03562806728688859\n",
      "train loss:0.05322839888705817\n",
      "train loss:0.035616376011378084\n",
      "train loss:0.07965876233058462\n",
      "train loss:0.017755081075039248\n",
      "train loss:0.07979674370647438\n",
      "train loss:0.05279209870493834\n",
      "train loss:0.025490792150426326\n",
      "train loss:0.054145687764339895\n",
      "train loss:0.026741281595633333\n",
      "train loss:0.022046703368995498\n",
      "train loss:0.023426211463256883\n",
      "train loss:0.020934435602768343\n",
      "train loss:0.07277721188540498\n",
      "train loss:0.03448107751073035\n",
      "train loss:0.03600469287204619\n",
      "train loss:0.06573239030938527\n",
      "train loss:0.08213788216947572\n",
      "train loss:0.052541290864137925\n",
      "train loss:0.05512589729585682\n",
      "train loss:0.005118485539338611\n",
      "train loss:0.024391828661204887\n",
      "train loss:0.02138780970390429\n",
      "train loss:0.04361399444393296\n",
      "train loss:0.06861825518277583\n",
      "train loss:0.0631236692434139\n",
      "train loss:0.04953356769086674\n",
      "train loss:0.01897118998618756\n",
      "train loss:0.056794437756907824\n",
      "train loss:0.009020323049108075\n",
      "train loss:0.02328107585540879\n",
      "train loss:0.06307588812303554\n",
      "train loss:0.01980065624927702\n",
      "train loss:0.0688888706344428\n",
      "train loss:0.08385388549029374\n",
      "train loss:0.09343569911814885\n",
      "train loss:0.008918603900869728\n",
      "train loss:0.17720822811492198\n",
      "train loss:0.017653457551703052\n",
      "train loss:0.023772821362051732\n",
      "train loss:0.03847719599062758\n",
      "train loss:0.05771948349905525\n",
      "train loss:0.055530935151569885\n",
      "train loss:0.038837064122912233\n",
      "train loss:0.03356680098101906\n",
      "train loss:0.03488177644285469\n",
      "train loss:0.037027662636023494\n",
      "train loss:0.12244397917436173\n",
      "train loss:0.014950414366553864\n",
      "train loss:0.024185066124836747\n",
      "train loss:0.04759205587531693\n",
      "train loss:0.011408074508720296\n",
      "train loss:0.08975872705500204\n",
      "train loss:0.035887037282903475\n",
      "train loss:0.054855938329385644\n",
      "train loss:0.08098589289070984\n",
      "train loss:0.01998481481630364\n",
      "train loss:0.035026479299785314\n",
      "train loss:0.0452890225622312\n",
      "train loss:0.01294167627907342\n",
      "train loss:0.034790050521455965\n",
      "train loss:0.11918010473450386\n",
      "train loss:0.0336033670798068\n",
      "train loss:0.039110923255451714\n",
      "train loss:0.017927704482304838\n",
      "train loss:0.026206580908001015\n",
      "train loss:0.044561170502217536\n",
      "train loss:0.13514230781832987\n",
      "train loss:0.09776828274858554\n",
      "train loss:0.00907780367295422\n",
      "train loss:0.06753216899007612\n",
      "train loss:0.013959610828400153\n",
      "train loss:0.05138278448191094\n",
      "train loss:0.02616558970695138\n",
      "train loss:0.018361059604165505\n",
      "train loss:0.014831701300953279\n",
      "train loss:0.08437264431221614\n",
      "train loss:0.02632895106096736\n",
      "train loss:0.06898896628245331\n",
      "train loss:0.02413245644051934\n",
      "train loss:0.03908686052875211\n",
      "train loss:0.018911346075062636\n",
      "train loss:0.07963795208231524\n",
      "train loss:0.03569530422321921\n",
      "train loss:0.03474656854735542\n",
      "train loss:0.07153208541135844\n",
      "train loss:0.021501154022874683\n",
      "train loss:0.013795247878433732\n",
      "train loss:0.10093640600001155\n",
      "train loss:0.01879065688623645\n",
      "train loss:0.02537632047470206\n",
      "train loss:0.07129218597774212\n",
      "train loss:0.026340791331727505\n",
      "train loss:0.0332622967873846\n",
      "train loss:0.03222393565788883\n",
      "train loss:0.08669331587658474\n",
      "train loss:0.014285355718774427\n",
      "train loss:0.17380601923616618\n",
      "train loss:0.023455348461932788\n",
      "train loss:0.08629861254668407\n",
      "train loss:0.0204065860853236\n",
      "train loss:0.044071931610639756\n",
      "train loss:0.023870951435316923\n",
      "train loss:0.008345503260223546\n",
      "train loss:0.03298009664982262\n",
      "train loss:0.046919018317273936\n",
      "train loss:0.036909217049580806\n",
      "train loss:0.04391540738710911\n",
      "train loss:0.04793081366064828\n",
      "train loss:0.086365200161041\n",
      "train loss:0.059518500783126586\n",
      "train loss:0.09318512586470776\n",
      "train loss:0.05028285001954211\n",
      "train loss:0.01991569278079387\n",
      "train loss:0.054593529017889476\n",
      "train loss:0.10297483365179132\n",
      "train loss:0.020362000003608004\n",
      "train loss:0.027225697411398495\n",
      "train loss:0.039395056634674665\n",
      "train loss:0.019830348316279583\n",
      "train loss:0.03334782359079543\n",
      "train loss:0.09068304406062272\n",
      "train loss:0.08144345475981503\n",
      "train loss:0.013403871368702764\n",
      "train loss:0.03561057861233905\n",
      "train loss:0.012277025464490911\n",
      "train loss:0.09032554710780724\n",
      "train loss:0.05077733968934404\n",
      "train loss:0.07789847709179833\n",
      "train loss:0.04987783031085044\n",
      "train loss:0.012747226507059862\n",
      "train loss:0.047990719668493324\n",
      "train loss:0.03607889769620845\n",
      "train loss:0.029762662254607067\n",
      "train loss:0.06488384298268639\n",
      "train loss:0.036441230467033\n",
      "train loss:0.08116946923353789\n",
      "train loss:0.03432561163695435\n",
      "train loss:0.06467929562404513\n",
      "train loss:0.05955620057041056\n",
      "train loss:0.08390693487416137\n",
      "train loss:0.04739788464491756\n",
      "train loss:0.025444914485698446\n",
      "train loss:0.056466518734228914\n",
      "train loss:0.027593922484101353\n",
      "train loss:0.017092617301929843\n",
      "train loss:0.01955740500135426\n",
      "train loss:0.05863488204468571\n",
      "train loss:0.04511638446175287\n",
      "train loss:0.026584377460051097\n",
      "train loss:0.057155542976985406\n",
      "train loss:0.02939710520969561\n",
      "train loss:0.05807656343531566\n",
      "train loss:0.05441691947692189\n",
      "train loss:0.018649021722552804\n",
      "train loss:0.029174842799840978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0459880330001119\n",
      "train loss:0.06421811104515213\n",
      "train loss:0.015610328353869028\n",
      "train loss:0.05333425073375717\n",
      "train loss:0.061981524968567986\n",
      "train loss:0.030967297227738874\n",
      "train loss:0.022945771859245914\n",
      "train loss:0.04060244879846224\n",
      "train loss:0.0506083137467134\n",
      "train loss:0.05515710575446639\n",
      "train loss:0.037559716860971475\n",
      "train loss:0.015024739908615978\n",
      "train loss:0.025672732984416035\n",
      "train loss:0.0650001245165368\n",
      "train loss:0.10905580854266742\n",
      "train loss:0.018634965812245618\n",
      "train loss:0.04190381350752945\n",
      "train loss:0.053476896054568686\n",
      "train loss:0.03468323046509405\n",
      "train loss:0.031525710166728727\n",
      "train loss:0.0088865233649226\n",
      "train loss:0.0363204960721094\n",
      "train loss:0.051263531385150454\n",
      "train loss:0.03235147944317522\n",
      "train loss:0.09473913997057308\n",
      "train loss:0.006455011536304028\n",
      "train loss:0.1311093822572037\n",
      "train loss:0.08010838303765842\n",
      "train loss:0.11035017354250551\n",
      "train loss:0.03173801587370867\n",
      "train loss:0.05231001049671269\n",
      "train loss:0.029098350654359176\n",
      "train loss:0.09154119114693719\n",
      "train loss:0.019247605934502497\n",
      "train loss:0.033098402661121004\n",
      "train loss:0.07050399106754393\n",
      "train loss:0.10421057974345287\n",
      "train loss:0.025155529783280225\n",
      "train loss:0.07705214538311117\n",
      "train loss:0.023269383200176907\n",
      "train loss:0.030853779334558493\n",
      "train loss:0.016861652788731127\n",
      "train loss:0.0813593746304911\n",
      "train loss:0.09747877608165055\n",
      "train loss:0.073119904179413\n",
      "train loss:0.045854158243566444\n",
      "train loss:0.04293996085451915\n",
      "train loss:0.026314847138332164\n",
      "train loss:0.0718239602930682\n",
      "train loss:0.053310757912824684\n",
      "train loss:0.04953928085432805\n",
      "train loss:0.0344573985088338\n",
      "train loss:0.04728771958131727\n",
      "train loss:0.010149206836227762\n",
      "train loss:0.058101515337635974\n",
      "train loss:0.05210327684742802\n",
      "train loss:0.03631251302841987\n",
      "train loss:0.02545552259127934\n",
      "train loss:0.019771058057208475\n",
      "train loss:0.01109129063955979\n",
      "train loss:0.050263210561355784\n",
      "train loss:0.01046665686089225\n",
      "train loss:0.0991866310120612\n",
      "train loss:0.02861176647233431\n",
      "train loss:0.043405716898110853\n",
      "train loss:0.036722798845804545\n",
      "train loss:0.0662661206896561\n",
      "train loss:0.019952583970028213\n",
      "train loss:0.010309490093827159\n",
      "train loss:0.0275254707244894\n",
      "train loss:0.012786283865076969\n",
      "train loss:0.013063539850832567\n",
      "train loss:0.018205453783187442\n",
      "train loss:0.0668145976261835\n",
      "train loss:0.02243379549643417\n",
      "train loss:0.04647299196189105\n",
      "train loss:0.10106870403169936\n",
      "train loss:0.031351716954692084\n",
      "train loss:0.015302949269986927\n",
      "train loss:0.03196908188270904\n",
      "train loss:0.06966948812334302\n",
      "train loss:0.040228631591569544\n",
      "train loss:0.0309660124763887\n",
      "train loss:0.08334382914111173\n",
      "train loss:0.0164352418128516\n",
      "train loss:0.05793273165259725\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9778\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  #       \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from dataset.mnist import load_mnist\n",
    "from CNN_simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "#  \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "#      .\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 5\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 10, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "#  \n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "#  \n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
